{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haripranesh1505/Speech-Emotion-Recognization/blob/main/Speech_Emotion_Recongnization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krmjQKW0f8xk"
      },
      "source": [
        "Speech Emotion Recongnization\n",
        "\n",
        "Hari Pranesh M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0MsJIWgXut8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e0e793-1908-425a-ebb6-c38f1801ac60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rSku0_cX3dB"
      },
      "outputs": [],
      "source": [
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# all emotions on RAVDESS dataset\n",
        "int2emotion = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "# we allow only these emotions\n",
        "AVAILABLE_EMOTIONS = {\n",
        "    \"angry\",\n",
        "    \"sad\",\n",
        "    \"neutral\",\n",
        "    \"happy\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWJ9phRhUDrM"
      },
      "outputs": [],
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "        if contrast:\n",
        "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, contrast))\n",
        "        if tonnetz:\n",
        "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, tonnetz))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI3q89z5YLVq"
      },
      "outputs": [],
      "source": [
        "def load_data(test_size=0.2):\n",
        "    X, y = [], []\n",
        "    try :\n",
        "      for file in glob.glob(\"/content/drive/My Drive/DataSets/audio_speech_actors_01-24/Actor_*/*.wav\"):\n",
        "          # get the base name of the audio file\n",
        "          basename = os.path.basename(file)\n",
        "          print(basename)\n",
        "          # get the emotion label\n",
        "          emotion = int2emotion[basename.split(\"-\")[2]]\n",
        "          # we allow only AVAILABLE_EMOTIONS we set\n",
        "          if emotion not in AVAILABLE_EMOTIONS:\n",
        "              continue\n",
        "          # extract speech features\n",
        "          features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "          # add to data\n",
        "          X.append(features)\n",
        "          l={'happy':0.0,'sad':1.0,'neutral':3.0,'angry':4.0}\n",
        "          y.append(l[emotion])\n",
        "    except :\n",
        "         pass\n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7USodbIYQli",
        "outputId": "52cee134-bfdc-4ea2-9622-fb1f4a3a1e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03-01-05-02-02-02-01.wav\n",
            "03-01-02-02-02-01-01.wav\n",
            "03-01-03-01-01-01-01.wav\n",
            "03-01-03-02-01-01-01.wav\n",
            "03-01-02-01-01-02-01.wav\n",
            "03-01-06-01-01-02-01.wav\n",
            "03-01-01-01-01-02-01.wav\n",
            "03-01-01-01-02-01-01.wav\n",
            "03-01-04-01-01-01-01.wav\n",
            "03-01-04-01-02-01-01.wav\n",
            "03-01-04-02-02-02-01.wav\n",
            "03-01-02-02-01-01-01.wav\n",
            "03-01-02-02-02-02-01.wav\n",
            "03-01-02-01-01-01-01.wav\n",
            "03-01-03-01-01-02-01.wav\n",
            "03-01-03-01-02-01-01.wav\n",
            "03-01-01-01-01-01-01.wav\n",
            "03-01-05-01-01-01-01.wav\n",
            "03-01-04-02-02-01-01.wav\n",
            "03-01-03-02-02-01-01.wav\n",
            "03-01-01-01-02-02-01.wav\n",
            "03-01-05-02-01-01-01.wav\n",
            "03-01-04-01-02-02-01.wav\n",
            "03-01-05-02-02-01-01.wav\n",
            "03-01-02-01-02-01-01.wav\n",
            "03-01-04-01-01-02-01.wav\n",
            "03-01-03-02-01-02-01.wav\n",
            "03-01-05-01-02-01-01.wav\n",
            "03-01-02-01-02-02-01.wav\n",
            "03-01-03-01-02-02-01.wav\n",
            "03-01-04-02-01-01-01.wav\n",
            "03-01-03-02-02-02-01.wav\n",
            "03-01-02-02-01-02-01.wav\n",
            "03-01-05-02-01-02-01.wav\n",
            "03-01-05-01-01-02-01.wav\n",
            "03-01-04-02-01-02-01.wav\n",
            "03-01-05-01-02-02-01.wav\n",
            "03-01-06-01-01-01-01.wav\n",
            "03-01-08-01-01-02-01.wav\n",
            "03-01-08-01-02-01-01.wav\n",
            "03-01-07-01-01-02-01.wav\n",
            "03-01-07-01-01-01-01.wav\n",
            "03-01-06-02-01-02-01.wav\n",
            "03-01-08-01-01-01-01.wav\n",
            "03-01-06-02-01-01-01.wav\n",
            "03-01-07-01-02-01-01.wav\n",
            "03-01-06-01-02-01-01.wav\n",
            "03-01-07-02-01-01-01.wav\n",
            "03-01-06-02-02-01-01.wav\n",
            "03-01-07-02-01-02-01.wav\n",
            "03-01-08-02-01-02-01.wav\n",
            "03-01-07-02-02-02-01.wav\n",
            "03-01-08-02-02-01-01.wav\n",
            "03-01-08-01-02-02-01.wav\n",
            "03-01-07-01-02-02-01.wav\n",
            "03-01-08-02-02-02-01.wav\n",
            "03-01-06-02-02-02-01.wav\n",
            "03-01-08-02-01-01-01.wav\n",
            "03-01-06-01-02-02-01.wav\n",
            "03-01-07-02-02-01-01.wav\n",
            "03-01-05-01-02-02-02.wav\n",
            "03-01-08-02-01-01-02.wav\n",
            "03-01-07-02-01-02-02.wav\n",
            "03-01-02-02-02-01-02.wav\n",
            "03-01-03-02-02-02-02.wav\n",
            "03-01-02-02-01-01-02.wav\n",
            "03-01-08-01-02-01-02.wav\n",
            "03-01-07-02-02-01-02.wav\n",
            "03-01-05-01-02-01-02.wav\n",
            "03-01-05-02-02-01-02.wav\n",
            "03-01-07-02-01-01-02.wav\n",
            "03-01-07-01-01-01-02.wav\n",
            "03-01-06-01-01-01-02.wav\n",
            "03-01-08-01-01-02-02.wav\n",
            "03-01-04-02-02-01-02.wav\n",
            "03-01-07-01-01-02-02.wav\n",
            "03-01-01-01-01-02-02.wav\n",
            "03-01-05-02-01-02-02.wav\n",
            "03-01-03-02-02-01-02.wav\n",
            "03-01-08-02-02-01-02.wav\n",
            "03-01-08-02-01-02-02.wav\n",
            "03-01-07-01-02-01-02.wav\n",
            "03-01-01-01-02-01-02.wav\n",
            "03-01-05-02-02-02-02.wav\n",
            "03-01-02-01-02-01-02.wav\n",
            "03-01-06-02-01-01-02.wav\n",
            "03-01-06-01-01-02-02.wav\n",
            "03-01-01-01-02-02-02.wav\n",
            "03-01-02-01-02-02-02.wav\n",
            "03-01-06-02-02-01-02.wav\n",
            "03-01-06-01-02-01-02.wav\n",
            "03-01-04-01-01-02-02.wav\n",
            "03-01-02-02-02-02-02.wav\n",
            "03-01-04-01-02-01-02.wav\n",
            "03-01-03-01-01-02-02.wav\n",
            "03-01-08-02-02-02-02.wav\n",
            "03-01-04-02-02-02-02.wav\n",
            "03-01-07-02-02-02-02.wav\n",
            "03-01-05-01-01-01-02.wav\n",
            "03-01-01-01-01-01-02.wav\n",
            "03-01-05-01-01-02-02.wav\n",
            "03-01-08-01-02-02-02.wav\n",
            "03-01-04-02-01-01-02.wav\n",
            "03-01-06-02-02-02-02.wav\n",
            "03-01-06-02-01-02-02.wav\n",
            "03-01-04-01-02-02-02.wav\n",
            "03-01-05-02-01-01-02.wav\n",
            "03-01-03-01-02-01-02.wav\n",
            "03-01-04-02-01-02-02.wav\n",
            "03-01-02-02-01-02-02.wav\n",
            "03-01-02-01-01-02-02.wav\n",
            "03-01-06-01-02-02-02.wav\n",
            "03-01-04-01-01-01-02.wav\n",
            "03-01-03-02-01-02-02.wav\n",
            "03-01-02-01-01-01-02.wav\n",
            "03-01-07-01-02-02-02.wav\n",
            "03-01-03-02-01-01-02.wav\n",
            "03-01-03-01-01-01-02.wav\n",
            "03-01-08-01-01-01-02.wav\n",
            "03-01-03-01-02-02-02.wav\n",
            "03-01-06-01-01-02-03.wav\n",
            "03-01-06-02-01-02-03.wav\n",
            "03-01-02-02-02-02-03.wav\n",
            "03-01-04-02-02-01-03.wav\n",
            "03-01-03-01-01-01-03.wav\n",
            "03-01-03-01-02-02-03.wav\n",
            "03-01-02-02-01-02-03.wav\n",
            "03-01-04-01-02-01-03.wav\n",
            "03-01-08-01-02-01-03.wav\n",
            "03-01-07-02-01-02-03.wav\n",
            "03-01-02-01-01-01-03.wav\n",
            "03-01-03-02-01-02-03.wav\n",
            "03-01-03-02-02-01-03.wav\n",
            "03-01-08-02-01-01-03.wav\n",
            "03-01-03-01-01-02-03.wav\n",
            "03-01-04-02-01-01-03.wav\n",
            "03-01-04-01-02-02-03.wav\n",
            "03-01-07-01-02-02-03.wav\n",
            "03-01-06-02-02-01-03.wav\n",
            "03-01-08-02-01-02-03.wav\n",
            "03-01-07-02-02-02-03.wav\n",
            "03-01-05-01-02-02-03.wav\n",
            "03-01-08-01-01-02-03.wav\n",
            "03-01-06-01-01-01-03.wav\n",
            "03-01-08-02-02-01-03.wav\n",
            "03-01-06-01-02-02-03.wav\n",
            "03-01-05-01-01-01-03.wav\n",
            "03-01-06-01-02-01-03.wav\n",
            "03-01-04-01-01-01-03.wav\n",
            "03-01-04-01-01-02-03.wav\n",
            "03-01-02-02-02-01-03.wav\n",
            "03-01-05-02-01-01-03.wav\n",
            "03-01-03-01-02-01-03.wav\n",
            "03-01-02-02-01-01-03.wav\n",
            "03-01-07-01-01-01-03.wav\n",
            "03-01-05-02-02-01-03.wav\n",
            "03-01-02-01-02-01-03.wav\n",
            "03-01-02-01-01-02-03.wav\n",
            "03-01-01-01-02-01-03.wav\n",
            "03-01-04-02-01-02-03.wav\n",
            "03-01-04-02-02-02-03.wav\n",
            "03-01-01-01-02-02-03.wav\n",
            "03-01-05-01-02-01-03.wav\n",
            "03-01-01-01-01-01-03.wav\n",
            "03-01-03-02-02-02-03.wav\n",
            "03-01-05-02-02-02-03.wav\n",
            "03-01-05-01-01-02-03.wav\n",
            "03-01-07-01-01-02-03.wav\n",
            "03-01-07-02-01-01-03.wav\n",
            "03-01-06-02-02-02-03.wav\n",
            "03-01-03-02-01-01-03.wav\n",
            "03-01-02-01-02-02-03.wav\n",
            "03-01-07-01-02-01-03.wav\n",
            "03-01-07-02-02-01-03.wav\n",
            "03-01-08-01-01-01-03.wav\n",
            "03-01-08-01-02-02-03.wav\n",
            "03-01-01-01-01-02-03.wav\n",
            "03-01-08-02-02-02-03.wav\n",
            "03-01-05-02-01-02-03.wav\n",
            "03-01-06-02-01-01-03.wav\n",
            "03-01-07-01-02-02-04.wav\n",
            "03-01-08-01-01-02-04.wav\n",
            "03-01-06-01-01-01-04.wav\n",
            "03-01-07-01-02-01-04.wav\n",
            "03-01-01-01-01-02-04.wav\n",
            "03-01-07-02-01-01-04.wav\n",
            "03-01-07-01-01-02-04.wav\n",
            "03-01-01-01-02-02-04.wav\n",
            "03-01-03-01-01-02-04.wav\n",
            "03-01-05-01-01-02-04.wav\n",
            "03-01-06-02-01-01-04.wav\n",
            "03-01-08-02-01-02-04.wav\n",
            "03-01-04-01-02-01-04.wav\n",
            "03-01-08-02-02-01-04.wav\n",
            "03-01-05-02-02-02-04.wav\n",
            "03-01-06-02-02-02-04.wav\n",
            "03-01-02-01-02-01-04.wav\n",
            "03-01-03-01-02-01-04.wav\n",
            "03-01-03-02-01-02-04.wav\n",
            "03-01-08-02-01-01-04.wav\n",
            "03-01-03-02-01-01-04.wav\n",
            "03-01-05-01-02-01-04.wav\n",
            "03-01-01-01-01-01-04.wav\n",
            "03-01-04-01-01-02-04.wav\n",
            "03-01-06-02-01-02-04.wav\n",
            "03-01-07-01-01-01-04.wav\n",
            "03-01-06-01-02-02-04.wav\n",
            "03-01-02-02-01-01-04.wav\n",
            "03-01-05-02-01-02-04.wav\n",
            "03-01-05-01-01-01-04.wav\n",
            "03-01-08-02-02-02-04.wav\n",
            "03-01-06-01-01-02-04.wav\n",
            "03-01-04-02-02-01-04.wav\n",
            "03-01-04-02-02-02-04.wav\n",
            "03-01-05-01-02-02-04.wav\n",
            "03-01-07-02-02-01-04.wav\n",
            "03-01-02-01-01-02-04.wav\n",
            "03-01-03-01-02-02-04.wav\n",
            "03-01-08-01-02-01-04.wav\n",
            "03-01-03-01-01-01-04.wav\n",
            "03-01-04-02-01-02-04.wav\n",
            "03-01-01-01-02-01-04.wav\n",
            "03-01-04-01-02-02-04.wav\n",
            "03-01-02-02-02-01-04.wav\n",
            "03-01-07-02-01-02-04.wav\n",
            "03-01-04-01-01-01-04.wav\n",
            "03-01-08-01-02-02-04.wav\n",
            "03-01-03-02-02-01-04.wav\n",
            "03-01-07-02-02-02-04.wav\n",
            "03-01-05-02-01-01-04.wav\n",
            "03-01-08-01-01-01-04.wav\n",
            "03-01-03-02-02-02-04.wav\n",
            "03-01-05-02-02-01-04.wav\n",
            "03-01-04-02-01-01-04.wav\n",
            "03-01-02-02-02-02-04.wav\n",
            "03-01-06-01-02-01-04.wav\n",
            "03-01-06-02-02-01-04.wav\n",
            "03-01-02-01-01-01-04.wav\n",
            "03-01-02-02-01-02-04.wav\n",
            "03-01-02-01-02-02-04.wav\n",
            "03-01-01-01-01-01-05.wav\n",
            "03-01-01-01-01-02-05.wav\n",
            "03-01-02-01-01-02-05.wav\n",
            "03-01-02-01-01-01-05.wav\n",
            "03-01-01-01-02-02-05.wav\n",
            "03-01-01-01-02-01-05.wav\n",
            "03-01-08-02-02-01-05.wav\n",
            "03-01-06-02-01-02-05.wav\n",
            "03-01-07-02-02-01-05.wav\n",
            "03-01-05-01-02-01-05.wav\n",
            "03-01-08-01-01-01-05.wav\n",
            "03-01-02-02-01-02-05.wav\n",
            "03-01-05-02-02-02-05.wav\n",
            "03-01-03-02-01-02-05.wav\n",
            "03-01-02-01-02-02-05.wav\n",
            "03-01-06-01-01-02-05.wav\n",
            "03-01-05-01-02-02-05.wav\n",
            "03-01-05-01-01-01-05.wav\n",
            "03-01-04-02-02-02-05.wav\n",
            "03-01-02-02-01-01-05.wav\n",
            "03-01-03-02-02-02-05.wav\n",
            "03-01-06-02-02-01-05.wav\n",
            "03-01-07-01-01-01-05.wav\n",
            "03-01-04-01-01-02-05.wav\n",
            "03-01-03-01-01-02-05.wav\n",
            "03-01-08-02-01-02-05.wav\n",
            "03-01-08-01-02-02-05.wav\n",
            "03-01-05-02-01-01-05.wav\n",
            "03-01-07-02-01-02-05.wav\n",
            "03-01-06-02-02-02-05.wav\n",
            "03-01-04-02-01-02-05.wav\n",
            "03-01-05-02-02-01-05.wav\n",
            "03-01-03-01-02-01-05.wav\n",
            "03-01-08-01-02-01-05.wav\n",
            "03-01-02-02-02-02-05.wav\n",
            "03-01-07-02-02-02-05.wav\n",
            "03-01-03-01-01-01-05.wav\n",
            "03-01-04-01-02-01-05.wav\n",
            "03-01-07-01-01-02-05.wav\n",
            "03-01-08-01-01-02-05.wav\n",
            "03-01-04-02-02-01-05.wav\n",
            "03-01-03-02-01-01-05.wav\n",
            "03-01-04-01-01-01-05.wav\n",
            "03-01-02-01-02-01-05.wav\n",
            "03-01-05-02-01-02-05.wav\n",
            "03-01-08-02-02-02-05.wav\n",
            "03-01-07-02-01-01-05.wav\n",
            "03-01-06-01-01-01-05.wav\n",
            "03-01-06-01-02-02-05.wav\n",
            "03-01-02-02-02-01-05.wav\n",
            "03-01-04-02-01-01-05.wav\n",
            "03-01-04-01-02-02-05.wav\n",
            "03-01-08-02-01-01-05.wav\n",
            "03-01-05-01-01-02-05.wav\n",
            "03-01-06-02-01-01-05.wav\n",
            "03-01-07-01-02-02-05.wav\n",
            "03-01-03-02-02-01-05.wav\n",
            "03-01-03-01-02-02-05.wav\n",
            "03-01-07-01-02-01-05.wav\n",
            "03-01-06-01-02-01-05.wav\n",
            "03-01-06-01-02-02-06.wav\n",
            "03-01-07-02-02-02-06.wav\n",
            "03-01-04-02-01-02-06.wav\n",
            "03-01-03-01-02-01-06.wav\n",
            "03-01-07-02-01-02-06.wav\n",
            "03-01-04-02-02-02-06.wav\n",
            "03-01-03-01-02-02-06.wav\n",
            "03-01-08-02-02-01-06.wav\n",
            "03-01-01-01-01-02-06.wav\n",
            "03-01-05-02-01-01-06.wav\n",
            "03-01-06-02-01-01-06.wav\n",
            "03-01-05-02-02-01-06.wav\n",
            "03-01-02-02-01-01-06.wav\n",
            "03-01-03-02-01-02-06.wav\n",
            "03-01-08-01-01-01-06.wav\n",
            "03-01-06-01-02-01-06.wav\n",
            "03-01-02-01-01-01-06.wav\n",
            "03-01-03-02-01-01-06.wav\n",
            "03-01-04-01-02-01-06.wav\n",
            "03-01-02-01-02-01-06.wav\n",
            "03-01-05-01-01-02-06.wav\n",
            "03-01-04-02-02-01-06.wav\n",
            "03-01-01-01-02-01-06.wav\n",
            "03-01-02-02-02-02-06.wav\n",
            "03-01-08-02-01-02-06.wav\n",
            "03-01-03-01-01-01-06.wav\n",
            "03-01-08-02-01-01-06.wav\n",
            "03-01-07-01-01-01-06.wav\n",
            "03-01-06-02-02-02-06.wav\n",
            "03-01-05-01-02-02-06.wav\n",
            "03-01-06-02-02-01-06.wav\n",
            "03-01-05-01-02-01-06.wav\n",
            "03-01-08-02-02-02-06.wav\n",
            "03-01-02-01-01-02-06.wav\n",
            "03-01-02-02-01-02-06.wav\n",
            "03-01-03-02-02-01-06.wav\n",
            "03-01-02-01-02-02-06.wav\n",
            "03-01-05-02-02-02-06.wav\n",
            "03-01-07-01-02-01-06.wav\n",
            "03-01-07-02-02-01-06.wav\n",
            "03-01-07-01-02-02-06.wav\n",
            "03-01-01-01-01-01-06.wav\n",
            "03-01-06-02-01-02-06.wav\n",
            "03-01-08-01-02-01-06.wav\n",
            "03-01-07-01-01-02-06.wav\n",
            "03-01-07-02-01-01-06.wav\n",
            "03-01-08-01-02-02-06.wav\n",
            "03-01-05-01-01-01-06.wav\n",
            "03-01-05-02-01-02-06.wav\n",
            "03-01-04-01-01-01-06.wav\n",
            "03-01-04-02-01-01-06.wav\n",
            "03-01-01-01-02-02-06.wav\n",
            "03-01-06-01-01-02-06.wav\n",
            "03-01-06-01-01-01-06.wav\n",
            "03-01-03-02-02-02-06.wav\n",
            "03-01-04-01-02-02-06.wav\n",
            "03-01-03-01-01-02-06.wav\n",
            "03-01-04-01-01-02-06.wav\n",
            "03-01-08-01-01-02-06.wav\n",
            "03-01-02-02-02-01-06.wav\n",
            "03-01-06-02-02-02-07.wav\n",
            "03-01-03-02-01-02-07.wav\n",
            "03-01-05-02-01-01-07.wav\n",
            "03-01-08-02-02-01-07.wav\n",
            "03-01-05-01-02-02-07.wav\n",
            "03-01-06-02-02-01-07.wav\n",
            "03-01-05-01-02-01-07.wav\n",
            "03-01-07-01-01-01-07.wav\n",
            "03-01-05-02-02-02-07.wav\n",
            "03-01-03-02-02-01-07.wav\n",
            "03-01-02-01-01-02-07.wav\n",
            "03-01-02-02-02-01-07.wav\n",
            "03-01-08-02-02-02-07.wav\n",
            "03-01-06-01-01-02-07.wav\n",
            "03-01-08-01-02-02-07.wav\n",
            "03-01-03-01-02-01-07.wav\n",
            "03-01-02-02-02-02-07.wav\n",
            "03-01-04-02-01-01-07.wav\n",
            "03-01-05-01-01-02-07.wav\n",
            "03-01-04-02-01-02-07.wav\n",
            "03-01-05-02-01-02-07.wav\n",
            "03-01-02-02-01-02-07.wav\n",
            "03-01-03-01-01-02-07.wav\n",
            "03-01-07-02-01-02-07.wav\n",
            "03-01-05-02-02-01-07.wav\n",
            "03-01-01-01-02-01-07.wav\n",
            "03-01-03-02-01-01-07.wav\n",
            "03-01-06-01-02-02-07.wav\n",
            "03-01-07-02-02-01-07.wav\n",
            "03-01-04-01-02-02-07.wav\n",
            "03-01-06-01-02-01-07.wav\n",
            "03-01-08-01-01-01-07.wav\n",
            "03-01-03-01-01-01-07.wav\n",
            "03-01-07-02-01-01-07.wav\n",
            "03-01-07-02-02-02-07.wav\n",
            "03-01-06-01-01-01-07.wav\n",
            "03-01-06-02-01-01-07.wav\n",
            "03-01-03-02-02-02-07.wav\n",
            "03-01-08-02-01-01-07.wav\n",
            "03-01-02-02-01-01-07.wav\n",
            "03-01-06-02-01-02-07.wav\n",
            "03-01-07-01-01-02-07.wav\n",
            "03-01-04-02-02-01-07.wav\n",
            "03-01-05-01-01-01-07.wav\n",
            "03-01-03-01-02-02-07.wav\n",
            "03-01-08-01-01-02-07.wav\n",
            "03-01-07-01-02-02-07.wav\n",
            "03-01-04-02-02-02-07.wav\n",
            "03-01-02-01-02-02-07.wav\n",
            "03-01-08-02-01-02-07.wav\n",
            "03-01-07-01-02-01-07.wav\n",
            "03-01-01-01-01-01-07.wav\n",
            "03-01-08-01-02-01-07.wav\n",
            "03-01-04-01-01-01-07.wav\n",
            "03-01-04-01-02-01-07.wav\n",
            "03-01-02-01-02-01-07.wav\n",
            "03-01-01-01-02-02-07.wav\n",
            "03-01-02-01-01-01-07.wav\n",
            "03-01-04-01-01-02-07.wav\n",
            "03-01-01-01-01-02-07.wav\n",
            "03-01-02-01-01-02-08.wav\n",
            "03-01-04-01-02-02-08.wav\n",
            "03-01-04-02-01-01-08.wav\n",
            "03-01-04-02-01-02-08.wav\n",
            "03-01-03-02-02-01-08.wav\n",
            "03-01-02-02-02-02-08.wav\n",
            "03-01-01-01-02-01-08.wav\n",
            "03-01-04-01-01-02-08.wav\n",
            "03-01-02-02-02-01-08.wav\n",
            "03-01-02-02-01-02-08.wav\n",
            "03-01-02-01-01-01-08.wav\n",
            "03-01-03-02-01-02-08.wav\n",
            "03-01-04-01-02-01-08.wav\n",
            "03-01-02-01-02-02-08.wav\n",
            "03-01-03-02-02-02-08.wav\n",
            "03-01-01-01-02-02-08.wav\n",
            "03-01-04-01-01-01-08.wav\n",
            "03-01-03-01-01-02-08.wav\n",
            "03-01-03-01-01-01-08.wav\n",
            "03-01-03-01-02-02-08.wav\n",
            "03-01-01-01-01-02-08.wav\n",
            "03-01-02-02-01-01-08.wav\n",
            "03-01-02-01-02-01-08.wav\n",
            "03-01-03-01-02-01-08.wav\n",
            "03-01-03-02-01-01-08.wav\n",
            "03-01-01-01-01-01-08.wav\n",
            "03-01-07-02-02-01-08.wav\n",
            "03-01-07-01-02-01-08.wav\n",
            "03-01-05-01-01-01-08.wav\n",
            "03-01-04-02-02-01-08.wav\n",
            "03-01-05-01-02-01-08.wav\n",
            "03-01-06-02-01-02-08.wav\n",
            "03-01-05-02-01-02-08.wav\n",
            "03-01-08-01-01-01-08.wav\n",
            "03-01-07-02-01-01-08.wav\n",
            "03-01-07-02-01-02-08.wav\n",
            "03-01-04-02-02-02-08.wav\n",
            "03-01-08-02-02-02-08.wav\n",
            "03-01-06-01-01-02-08.wav\n",
            "03-01-08-02-02-01-08.wav\n",
            "03-01-08-01-02-01-08.wav\n",
            "03-01-05-01-01-02-08.wav\n",
            "03-01-05-02-01-01-08.wav\n",
            "03-01-05-02-02-01-08.wav\n",
            "03-01-08-02-01-02-08.wav\n",
            "03-01-08-01-01-02-08.wav\n",
            "03-01-07-01-01-02-08.wav\n",
            "03-01-06-01-02-02-08.wav\n",
            "03-01-07-01-01-01-08.wav\n",
            "03-01-05-02-02-02-08.wav\n",
            "03-01-06-02-01-01-08.wav\n",
            "03-01-05-01-02-02-08.wav\n",
            "03-01-08-01-02-02-08.wav\n",
            "03-01-06-02-02-02-08.wav\n",
            "03-01-07-02-02-02-08.wav\n",
            "03-01-06-02-02-01-08.wav\n",
            "03-01-06-01-02-01-08.wav\n",
            "03-01-08-02-01-01-08.wav\n",
            "03-01-07-01-02-02-08.wav\n",
            "03-01-06-01-01-01-08.wav\n",
            "03-01-01-01-01-02-09.wav\n",
            "03-01-06-01-01-02-09.wav\n",
            "03-01-05-02-01-01-09.wav\n",
            "03-01-07-02-01-01-09.wav\n",
            "03-01-06-01-02-01-09.wav\n",
            "03-01-03-01-02-01-09.wav\n",
            "03-01-06-01-01-01-09.wav\n",
            "03-01-04-02-02-01-09.wav\n",
            "03-01-02-01-02-01-09.wav\n",
            "03-01-02-02-01-02-09.wav\n",
            "03-01-02-01-01-02-09.wav\n",
            "03-01-05-01-02-02-09.wav\n",
            "03-01-07-01-01-02-09.wav\n",
            "03-01-06-02-01-02-09.wav\n",
            "03-01-05-01-01-02-09.wav\n",
            "03-01-05-01-02-01-09.wav\n",
            "03-01-02-01-01-01-09.wav\n",
            "03-01-02-02-02-02-09.wav\n",
            "03-01-04-01-02-02-09.wav\n",
            "03-01-06-02-02-01-09.wav\n",
            "03-01-01-01-01-01-09.wav\n",
            "03-01-08-02-02-01-09.wav\n",
            "03-01-07-01-02-02-09.wav\n",
            "03-01-02-02-02-01-09.wav\n",
            "03-01-02-01-02-02-09.wav\n",
            "03-01-07-01-01-01-09.wav\n",
            "03-01-03-02-01-01-09.wav\n",
            "03-01-02-02-01-01-09.wav\n",
            "03-01-05-02-01-02-09.wav\n",
            "03-01-01-01-02-01-09.wav\n",
            "03-01-04-01-02-01-09.wav\n",
            "03-01-04-02-01-01-09.wav\n",
            "03-01-08-02-01-01-09.wav\n",
            "03-01-01-01-02-02-09.wav\n",
            "03-01-08-02-02-02-09.wav\n",
            "03-01-08-01-01-01-09.wav\n",
            "03-01-04-02-01-02-09.wav\n",
            "03-01-04-02-02-02-09.wav\n",
            "03-01-07-01-02-01-09.wav\n",
            "03-01-08-01-01-02-09.wav\n",
            "03-01-07-02-02-02-09.wav\n",
            "03-01-05-01-01-01-09.wav\n",
            "03-01-08-01-02-01-09.wav\n",
            "03-01-04-01-01-01-09.wav\n",
            "03-01-07-02-02-01-09.wav\n",
            "03-01-03-02-02-02-09.wav\n",
            "03-01-08-02-01-02-09.wav\n",
            "03-01-03-01-02-02-09.wav\n",
            "03-01-06-02-02-02-09.wav\n",
            "03-01-06-01-02-02-09.wav\n",
            "03-01-05-02-02-01-09.wav\n",
            "03-01-04-01-01-02-09.wav\n",
            "03-01-03-01-01-02-09.wav\n",
            "03-01-08-01-02-02-09.wav\n",
            "03-01-07-02-01-02-09.wav\n",
            "03-01-05-02-02-02-09.wav\n",
            "03-01-03-02-01-02-09.wav\n",
            "03-01-06-02-01-01-09.wav\n",
            "03-01-03-02-02-01-09.wav\n",
            "03-01-03-01-01-01-09.wav\n",
            "03-01-02-02-01-01-10.wav\n",
            "03-01-07-01-01-02-10.wav\n",
            "03-01-06-02-01-01-10.wav\n",
            "03-01-03-01-01-02-10.wav\n",
            "03-01-07-02-01-01-10.wav\n",
            "03-01-07-02-01-02-10.wav\n",
            "03-01-04-01-02-01-10.wav\n",
            "03-01-04-02-01-01-10.wav\n",
            "03-01-04-01-01-01-10.wav\n",
            "03-01-06-02-02-02-10.wav\n",
            "03-01-08-02-01-01-10.wav\n",
            "03-01-02-01-01-01-10.wav\n",
            "03-01-08-01-01-01-10.wav\n",
            "03-01-08-01-02-02-10.wav\n",
            "03-01-06-01-02-01-10.wav\n",
            "03-01-05-02-01-01-10.wav\n",
            "03-01-02-02-01-02-10.wav\n",
            "03-01-05-01-02-01-10.wav\n",
            "03-01-06-01-01-02-10.wav\n",
            "03-01-02-02-02-01-10.wav\n",
            "03-01-08-02-02-01-10.wav\n",
            "03-01-05-01-01-01-10.wav\n",
            "03-01-02-02-02-02-10.wav\n",
            "03-01-08-02-02-02-10.wav\n",
            "03-01-04-02-02-01-10.wav\n",
            "03-01-05-01-01-02-10.wav\n",
            "03-01-03-02-01-01-10.wav\n",
            "03-01-07-01-02-02-10.wav\n",
            "03-01-05-02-02-02-10.wav\n",
            "03-01-03-02-01-02-10.wav\n",
            "03-01-06-02-02-01-10.wav\n",
            "03-01-02-01-02-01-10.wav\n",
            "03-01-01-01-02-02-10.wav\n",
            "03-01-02-01-02-02-10.wav\n",
            "03-01-03-01-02-02-10.wav\n",
            "03-01-05-02-01-02-10.wav\n",
            "03-01-06-01-01-01-10.wav\n",
            "03-01-03-02-02-01-10.wav\n",
            "03-01-08-01-01-02-10.wav\n",
            "03-01-04-02-02-02-10.wav\n",
            "03-01-01-01-02-01-10.wav\n",
            "03-01-04-01-02-02-10.wav\n",
            "03-01-07-01-02-01-10.wav\n",
            "03-01-06-01-02-02-10.wav\n",
            "03-01-02-01-01-02-10.wav\n",
            "03-01-03-01-01-01-10.wav\n",
            "03-01-08-01-02-01-10.wav\n",
            "03-01-07-02-02-01-10.wav\n",
            "03-01-07-02-02-02-10.wav\n",
            "03-01-05-01-02-02-10.wav\n",
            "03-01-04-01-01-02-10.wav\n",
            "03-01-04-02-01-02-10.wav\n",
            "03-01-01-01-01-01-10.wav\n",
            "03-01-03-02-02-02-10.wav\n",
            "03-01-03-01-02-01-10.wav\n",
            "03-01-07-01-01-01-10.wav\n",
            "03-01-01-01-01-02-10.wav\n",
            "03-01-06-02-01-02-10.wav\n",
            "03-01-05-02-02-01-10.wav\n",
            "03-01-08-02-01-02-10.wav\n",
            "03-01-02-01-01-02-11.wav\n",
            "03-01-03-01-01-01-11.wav\n",
            "03-01-06-02-02-02-11.wav\n",
            "03-01-01-01-01-01-11.wav\n",
            "03-01-07-01-01-02-11.wav\n",
            "03-01-03-01-02-02-11.wav\n",
            "03-01-03-01-02-01-11.wav\n",
            "03-01-01-01-02-02-11.wav\n",
            "03-01-04-01-01-01-11.wav\n",
            "03-01-05-02-02-02-11.wav\n",
            "03-01-05-01-01-01-11.wav\n",
            "03-01-03-02-01-02-11.wav\n",
            "03-01-03-02-02-02-11.wav\n",
            "03-01-05-02-01-01-11.wav\n",
            "03-01-02-02-01-02-11.wav\n",
            "03-01-02-02-02-01-11.wav\n",
            "03-01-07-01-02-01-11.wav\n",
            "03-01-01-01-01-02-11.wav\n",
            "03-01-05-02-02-01-11.wav\n",
            "03-01-01-01-02-01-11.wav\n",
            "03-01-06-02-01-02-11.wav\n",
            "03-01-04-01-01-02-11.wav\n",
            "03-01-03-02-02-01-11.wav\n",
            "03-01-07-02-01-01-11.wav\n",
            "03-01-05-01-02-02-11.wav\n",
            "03-01-06-02-02-01-11.wav\n",
            "03-01-05-02-01-02-11.wav\n",
            "03-01-04-02-02-02-11.wav\n",
            "03-01-04-02-01-01-11.wav\n",
            "03-01-03-01-01-02-11.wav\n",
            "03-01-06-01-02-01-11.wav\n",
            "03-01-06-01-01-02-11.wav\n",
            "03-01-07-02-01-02-11.wav\n",
            "03-01-06-01-01-01-11.wav\n",
            "03-01-02-01-01-01-11.wav\n",
            "03-01-05-01-01-02-11.wav\n",
            "03-01-04-01-02-02-11.wav\n",
            "03-01-04-01-02-01-11.wav\n",
            "03-01-03-02-01-01-11.wav\n",
            "03-01-04-02-02-01-11.wav\n",
            "03-01-04-02-01-02-11.wav\n",
            "03-01-06-01-02-02-11.wav\n",
            "03-01-02-02-02-02-11.wav\n",
            "03-01-05-01-02-01-11.wav\n",
            "03-01-02-01-02-02-11.wav\n",
            "03-01-06-02-01-01-11.wav\n",
            "03-01-02-02-01-01-11.wav\n",
            "03-01-07-01-01-01-11.wav\n",
            "03-01-07-01-02-02-11.wav\n",
            "03-01-02-01-02-01-11.wav\n",
            "03-01-07-02-02-01-11.wav\n",
            "03-01-08-01-02-01-11.wav\n",
            "03-01-08-02-01-02-11.wav\n",
            "03-01-08-02-01-01-11.wav\n",
            "03-01-08-01-01-01-11.wav\n",
            "03-01-07-02-02-02-11.wav\n",
            "03-01-08-01-02-02-11.wav\n",
            "03-01-08-02-02-02-11.wav\n",
            "03-01-08-01-01-02-11.wav\n",
            "03-01-08-02-02-01-11.wav\n",
            "03-01-04-02-01-02-12.wav\n",
            "03-01-07-02-01-01-12.wav\n",
            "03-01-08-02-02-01-12.wav\n",
            "03-01-06-01-01-02-12.wav\n",
            "03-01-07-02-01-02-12.wav\n",
            "03-01-07-01-02-01-12.wav\n",
            "03-01-02-02-02-02-12.wav\n",
            "03-01-07-01-01-01-12.wav\n",
            "03-01-04-02-02-02-12.wav\n",
            "03-01-02-01-01-01-12.wav\n",
            "03-01-02-02-02-01-12.wav\n",
            "03-01-06-01-02-01-12.wav\n",
            "03-01-08-01-01-02-12.wav\n",
            "03-01-01-01-02-01-12.wav\n",
            "03-01-02-02-01-01-12.wav\n",
            "03-01-03-02-02-02-12.wav\n",
            "03-01-02-01-01-02-12.wav\n",
            "03-01-05-01-01-01-12.wav\n",
            "03-01-08-01-02-02-12.wav\n",
            "03-01-04-02-02-01-12.wav\n",
            "03-01-04-01-01-01-12.wav\n",
            "03-01-06-02-01-02-12.wav\n",
            "03-01-03-01-01-02-12.wav\n",
            "03-01-05-02-01-01-12.wav\n",
            "03-01-04-01-01-02-12.wav\n",
            "03-01-08-02-01-01-12.wav\n",
            "03-01-06-01-02-02-12.wav\n",
            "03-01-08-01-02-01-12.wav\n",
            "03-01-05-01-01-02-12.wav\n",
            "03-01-02-01-02-01-12.wav\n",
            "03-01-06-02-02-01-12.wav\n",
            "03-01-03-02-01-02-12.wav\n",
            "03-01-01-01-01-01-12.wav\n",
            "03-01-05-01-02-01-12.wav\n",
            "03-01-03-02-01-01-12.wav\n",
            "03-01-08-02-01-02-12.wav\n",
            "03-01-08-01-01-01-12.wav\n",
            "03-01-01-01-02-02-12.wav\n",
            "03-01-03-02-02-01-12.wav\n",
            "03-01-06-01-01-01-12.wav\n",
            "03-01-04-02-01-01-12.wav\n",
            "03-01-05-02-02-01-12.wav\n",
            "03-01-06-02-01-01-12.wav\n",
            "03-01-03-01-02-02-12.wav\n",
            "03-01-02-02-01-02-12.wav\n",
            "03-01-01-01-01-02-12.wav\n",
            "03-01-05-02-01-02-12.wav\n",
            "03-01-04-01-02-02-12.wav\n",
            "03-01-07-02-02-02-12.wav\n",
            "03-01-07-02-02-01-12.wav\n",
            "03-01-07-01-02-02-12.wav\n",
            "03-01-04-01-02-01-12.wav\n",
            "03-01-05-01-02-02-12.wav\n",
            "03-01-05-02-02-02-12.wav\n",
            "03-01-06-02-02-02-12.wav\n",
            "03-01-03-01-01-01-12.wav\n",
            "03-01-08-02-02-02-12.wav\n",
            "03-01-07-01-01-02-12.wav\n",
            "03-01-02-01-02-02-12.wav\n",
            "03-01-03-01-02-01-12.wav\n",
            "03-01-08-01-01-01-13.wav\n",
            "03-01-04-01-02-01-13.wav\n",
            "03-01-06-02-02-01-13.wav\n",
            "03-01-01-01-02-01-13.wav\n",
            "03-01-05-01-01-02-13.wav\n",
            "03-01-07-02-01-02-13.wav\n",
            "03-01-01-01-01-02-13.wav\n",
            "03-01-05-02-02-01-13.wav\n",
            "03-01-02-01-01-01-13.wav\n",
            "03-01-04-02-01-01-13.wav\n",
            "03-01-01-01-01-01-13.wav\n",
            "03-01-04-01-02-02-13.wav\n",
            "03-01-05-02-02-02-13.wav\n",
            "03-01-03-02-02-02-13.wav\n",
            "03-01-08-02-01-01-13.wav\n",
            "03-01-05-01-01-01-13.wav\n",
            "03-01-03-02-02-01-13.wav\n",
            "03-01-02-01-02-01-13.wav\n",
            "03-01-05-01-02-02-13.wav\n",
            "03-01-02-02-01-02-13.wav\n",
            "03-01-03-02-01-01-13.wav\n",
            "03-01-04-01-01-01-13.wav\n",
            "03-01-02-02-01-01-13.wav\n",
            "03-01-08-01-02-01-13.wav\n",
            "03-01-05-01-02-01-13.wav\n",
            "03-01-03-01-01-02-13.wav\n",
            "03-01-06-01-01-01-13.wav\n",
            "03-01-08-01-02-02-13.wav\n",
            "03-01-02-01-02-02-13.wav\n",
            "03-01-08-01-01-02-13.wav\n",
            "03-01-07-02-02-02-13.wav\n",
            "03-01-03-02-01-02-13.wav\n",
            "03-01-03-01-02-02-13.wav\n",
            "03-01-06-02-01-01-13.wav\n",
            "03-01-06-02-01-02-13.wav\n",
            "03-01-06-01-02-01-13.wav\n",
            "03-01-03-01-02-01-13.wav\n",
            "03-01-06-02-02-02-13.wav\n",
            "03-01-02-02-02-02-13.wav\n",
            "03-01-05-02-01-01-13.wav\n",
            "03-01-07-01-01-02-13.wav\n",
            "03-01-06-01-02-02-13.wav\n",
            "03-01-07-02-02-01-13.wav\n",
            "03-01-04-02-02-01-13.wav\n",
            "03-01-05-02-01-02-13.wav\n",
            "03-01-02-02-02-01-13.wav\n",
            "03-01-07-01-02-01-13.wav\n",
            "03-01-04-02-01-02-13.wav\n",
            "03-01-08-02-01-02-13.wav\n",
            "03-01-07-01-01-01-13.wav\n",
            "03-01-07-02-01-01-13.wav\n",
            "03-01-03-01-01-01-13.wav\n",
            "03-01-06-01-01-02-13.wav\n",
            "03-01-04-01-01-02-13.wav\n",
            "03-01-01-01-02-02-13.wav\n",
            "03-01-08-02-02-01-13.wav\n",
            "03-01-08-02-02-02-13.wav\n",
            "03-01-04-02-02-02-13.wav\n",
            "03-01-02-01-01-02-13.wav\n",
            "03-01-07-01-02-02-13.wav\n",
            "03-01-08-02-02-01-14.wav\n",
            "03-01-04-02-02-02-14.wav\n",
            "03-01-06-02-02-01-14.wav\n",
            "03-01-05-02-01-01-14.wav\n",
            "03-01-03-01-02-01-14.wav\n",
            "03-01-04-02-02-01-14.wav\n",
            "03-01-02-01-01-02-14.wav\n",
            "03-01-08-01-02-01-14.wav\n",
            "03-01-04-01-02-01-14.wav\n",
            "03-01-07-02-02-01-14.wav\n",
            "03-01-07-02-01-01-14.wav\n",
            "03-01-04-02-01-02-14.wav\n",
            "03-01-04-01-01-01-14.wav\n",
            "03-01-03-01-01-01-14.wav\n",
            "03-01-07-02-01-02-14.wav\n",
            "03-01-06-02-01-02-14.wav\n",
            "03-01-05-01-01-02-14.wav\n",
            "03-01-03-02-02-01-14.wav\n",
            "03-01-04-01-01-02-14.wav\n",
            "03-01-02-01-01-01-14.wav\n",
            "03-01-02-02-02-01-14.wav\n",
            "03-01-06-02-02-02-14.wav\n",
            "03-01-06-01-01-02-14.wav\n",
            "03-01-08-01-02-02-14.wav\n",
            "03-01-06-02-01-01-14.wav\n",
            "03-01-07-01-01-02-14.wav\n",
            "03-01-08-02-02-02-14.wav\n",
            "03-01-02-02-02-02-14.wav\n",
            "03-01-06-01-02-02-14.wav\n",
            "03-01-05-01-01-01-14.wav\n",
            "03-01-06-01-02-01-14.wav\n",
            "03-01-01-01-01-02-14.wav\n",
            "03-01-07-02-02-02-14.wav\n",
            "03-01-05-02-02-02-14.wav\n",
            "03-01-02-02-01-02-14.wav\n",
            "03-01-03-01-01-02-14.wav\n",
            "03-01-01-01-02-02-14.wav\n",
            "03-01-03-02-01-02-14.wav\n",
            "03-01-07-01-02-02-14.wav\n",
            "03-01-02-01-02-01-14.wav\n",
            "03-01-02-02-01-01-14.wav\n",
            "03-01-05-01-02-02-14.wav\n",
            "03-01-02-01-02-02-14.wav\n",
            "03-01-04-02-01-01-14.wav\n",
            "03-01-08-01-01-02-14.wav\n",
            "03-01-01-01-02-01-14.wav\n",
            "03-01-03-02-02-02-14.wav\n",
            "03-01-03-02-01-01-14.wav\n",
            "03-01-07-01-02-01-14.wav\n",
            "03-01-04-01-02-02-14.wav\n",
            "03-01-05-02-01-02-14.wav\n",
            "03-01-01-01-01-01-14.wav\n",
            "03-01-05-01-02-01-14.wav\n",
            "03-01-07-01-01-01-14.wav\n",
            "03-01-08-02-01-01-14.wav\n",
            "03-01-03-01-02-02-14.wav\n",
            "03-01-08-02-01-02-14.wav\n",
            "03-01-05-02-02-01-14.wav\n",
            "03-01-08-01-01-01-14.wav\n",
            "03-01-06-01-01-01-14.wav\n",
            "03-01-05-02-02-02-15.wav\n",
            "03-01-03-01-02-02-15.wav\n",
            "03-01-04-02-01-01-15.wav\n",
            "03-01-03-01-01-02-15.wav\n",
            "03-01-05-02-02-01-15.wav\n",
            "03-01-02-01-02-01-15.wav\n",
            "03-01-04-02-02-02-15.wav\n",
            "03-01-01-01-01-01-15.wav\n",
            "03-01-04-01-02-02-15.wav\n",
            "03-01-05-01-01-01-15.wav\n",
            "03-01-02-02-02-01-15.wav\n",
            "03-01-05-02-01-01-15.wav\n",
            "03-01-05-01-02-01-15.wav\n",
            "03-01-03-01-02-01-15.wav\n",
            "03-01-02-01-01-02-15.wav\n",
            "03-01-04-02-02-01-15.wav\n",
            "03-01-06-01-01-02-15.wav\n",
            "03-01-05-02-01-02-15.wav\n",
            "03-01-03-02-02-02-15.wav\n",
            "03-01-03-02-01-02-15.wav\n",
            "03-01-05-01-01-02-15.wav\n",
            "03-01-04-02-01-02-15.wav\n",
            "03-01-02-02-01-02-15.wav\n",
            "03-01-01-01-01-02-15.wav\n",
            "03-01-02-02-02-02-15.wav\n",
            "03-01-02-01-01-01-15.wav\n",
            "03-01-01-01-02-02-15.wav\n",
            "03-01-04-01-02-01-15.wav\n",
            "03-01-04-01-01-02-15.wav\n",
            "03-01-05-01-02-02-15.wav\n",
            "03-01-03-02-02-01-15.wav\n",
            "03-01-02-02-01-01-15.wav\n",
            "03-01-01-01-02-01-15.wav\n",
            "03-01-06-01-01-01-15.wav\n",
            "03-01-03-02-01-01-15.wav\n",
            "03-01-04-01-01-01-15.wav\n",
            "03-01-02-01-02-02-15.wav\n",
            "03-01-03-01-01-01-15.wav\n",
            "03-01-06-02-02-01-15.wav\n",
            "03-01-06-01-02-01-15.wav\n",
            "03-01-08-02-01-02-15.wav\n",
            "03-01-08-02-02-01-15.wav\n",
            "03-01-07-02-01-01-15.wav\n",
            "03-01-06-01-02-02-15.wav\n",
            "03-01-07-01-02-01-15.wav\n",
            "03-01-06-02-01-02-15.wav\n",
            "03-01-08-01-01-01-15.wav\n",
            "03-01-07-01-01-02-15.wav\n",
            "03-01-07-02-02-01-15.wav\n",
            "03-01-07-01-01-01-15.wav\n",
            "03-01-07-02-02-02-15.wav\n",
            "03-01-08-01-02-02-15.wav\n",
            "03-01-08-01-02-01-15.wav\n",
            "03-01-08-02-01-01-15.wav\n",
            "03-01-07-02-01-02-15.wav\n",
            "03-01-08-02-02-02-15.wav\n",
            "03-01-06-02-02-02-15.wav\n",
            "03-01-08-01-01-02-15.wav\n",
            "03-01-07-01-02-02-15.wav\n",
            "03-01-06-02-01-01-15.wav\n",
            "03-01-08-02-01-01-16.wav\n",
            "03-01-02-01-01-01-16.wav\n",
            "03-01-06-01-02-02-16.wav\n",
            "03-01-08-01-02-02-16.wav\n",
            "03-01-02-02-01-01-16.wav\n",
            "03-01-02-01-01-02-16.wav\n",
            "03-01-07-01-01-01-16.wav\n",
            "03-01-05-02-02-02-16.wav\n",
            "03-01-03-01-02-01-16.wav\n",
            "03-01-04-02-01-01-16.wav\n",
            "03-01-07-02-02-01-16.wav\n",
            "03-01-07-01-01-02-16.wav\n",
            "03-01-06-02-02-01-16.wav\n",
            "03-01-06-02-01-02-16.wav\n",
            "03-01-08-01-01-01-16.wav\n",
            "03-01-03-01-01-02-16.wav\n",
            "03-01-06-02-02-02-16.wav\n",
            "03-01-01-01-02-01-16.wav\n",
            "03-01-03-02-02-01-16.wav\n",
            "03-01-02-01-02-02-16.wav\n",
            "03-01-04-01-02-02-16.wav\n",
            "03-01-06-01-02-01-16.wav\n",
            "03-01-05-01-01-02-16.wav\n",
            "03-01-03-01-02-02-16.wav\n",
            "03-01-08-02-01-02-16.wav\n",
            "03-01-03-02-02-02-16.wav\n",
            "03-01-04-02-02-01-16.wav\n",
            "03-01-04-01-02-01-16.wav\n",
            "03-01-04-02-02-02-16.wav\n",
            "03-01-04-01-01-01-16.wav\n",
            "03-01-07-01-02-01-16.wav\n",
            "03-01-05-01-01-01-16.wav\n",
            "03-01-07-02-02-02-16.wav\n",
            "03-01-08-02-02-01-16.wav\n",
            "03-01-07-01-02-02-16.wav\n",
            "03-01-05-02-02-01-16.wav\n",
            "03-01-05-01-02-02-16.wav\n",
            "03-01-05-02-01-01-16.wav\n",
            "03-01-03-02-01-01-16.wav\n",
            "03-01-06-01-01-02-16.wav\n",
            "03-01-08-02-02-02-16.wav\n",
            "03-01-07-02-01-02-16.wav\n",
            "03-01-03-01-01-01-16.wav\n",
            "03-01-04-02-01-02-16.wav\n",
            "03-01-08-01-01-02-16.wav\n",
            "03-01-07-02-01-01-16.wav\n",
            "03-01-01-01-01-01-16.wav\n",
            "03-01-02-02-01-02-16.wav\n",
            "03-01-02-01-02-01-16.wav\n",
            "03-01-04-01-01-02-16.wav\n",
            "03-01-02-02-02-02-16.wav\n",
            "03-01-01-01-01-02-16.wav\n",
            "03-01-05-01-02-01-16.wav\n",
            "03-01-08-01-02-01-16.wav\n",
            "03-01-05-02-01-02-16.wav\n",
            "03-01-03-02-01-02-16.wav\n",
            "03-01-01-01-02-02-16.wav\n",
            "03-01-06-02-01-01-16.wav\n",
            "03-01-06-01-01-01-16.wav\n",
            "03-01-02-02-02-01-16.wav\n",
            "03-01-01-01-01-02-17.wav\n",
            "03-01-03-02-01-02-17.wav\n",
            "03-01-03-01-02-02-17.wav\n",
            "03-01-06-01-01-02-17.wav\n",
            "03-01-08-01-01-02-17.wav\n",
            "03-01-05-02-01-02-17.wav\n",
            "03-01-08-01-02-01-17.wav\n",
            "03-01-08-01-01-01-17.wav\n",
            "03-01-01-01-02-01-17.wav\n",
            "03-01-08-02-01-01-17.wav\n",
            "03-01-07-01-01-02-17.wav\n",
            "03-01-06-01-02-01-17.wav\n",
            "03-01-03-01-02-01-17.wav\n",
            "03-01-02-02-01-02-17.wav\n",
            "03-01-06-01-02-02-17.wav\n",
            "03-01-04-01-01-02-17.wav\n",
            "03-01-02-01-01-02-17.wav\n",
            "03-01-04-02-02-02-17.wav\n",
            "03-01-04-02-01-02-17.wav\n",
            "03-01-07-01-01-01-17.wav\n",
            "03-01-02-02-01-01-17.wav\n",
            "03-01-02-01-02-01-17.wav\n",
            "03-01-08-02-01-02-17.wav\n",
            "03-01-02-02-02-02-17.wav\n",
            "03-01-06-01-01-01-17.wav\n",
            "03-01-07-02-02-02-17.wav\n",
            "03-01-03-02-01-01-17.wav\n",
            "03-01-08-02-02-01-17.wav\n",
            "03-01-02-01-02-02-17.wav\n",
            "03-01-07-02-01-02-17.wav\n",
            "03-01-04-01-02-01-17.wav\n",
            "03-01-04-02-02-01-17.wav\n",
            "03-01-03-01-01-02-17.wav\n",
            "03-01-06-02-01-02-17.wav\n",
            "03-01-03-02-02-02-17.wav\n",
            "03-01-02-02-02-01-17.wav\n",
            "03-01-06-02-01-01-17.wav\n",
            "03-01-03-01-01-01-17.wav\n",
            "03-01-06-02-02-02-17.wav\n",
            "03-01-07-01-02-01-17.wav\n",
            "03-01-04-01-02-02-17.wav\n",
            "03-01-01-01-01-01-17.wav\n",
            "03-01-06-02-02-01-17.wav\n",
            "03-01-05-02-02-02-17.wav\n",
            "03-01-08-02-02-02-17.wav\n",
            "03-01-07-02-01-01-17.wav\n",
            "03-01-08-01-02-02-17.wav\n",
            "03-01-04-02-01-01-17.wav\n",
            "03-01-01-01-02-02-17.wav\n",
            "03-01-07-01-02-02-17.wav\n",
            "03-01-04-01-01-01-17.wav\n",
            "03-01-05-01-02-02-17.wav\n",
            "03-01-07-02-02-01-17.wav\n",
            "03-01-02-01-01-01-17.wav\n",
            "03-01-05-02-01-01-17.wav\n",
            "03-01-05-01-01-01-17.wav\n",
            "03-01-05-01-01-02-17.wav\n",
            "03-01-03-02-02-01-17.wav\n",
            "03-01-05-02-02-01-17.wav\n",
            "03-01-05-01-02-01-17.wav\n",
            "03-01-06-02-01-01-18.wav\n",
            "03-01-08-01-02-01-18.wav\n",
            "03-01-03-02-02-02-18.wav\n",
            "03-01-02-02-02-02-18.wav\n",
            "03-01-03-02-01-02-18.wav\n",
            "03-01-04-02-01-01-18.wav\n",
            "03-01-04-01-01-01-18.wav\n",
            "03-01-05-02-01-02-18.wav\n",
            "03-01-07-02-02-01-18.wav\n",
            "03-01-08-01-01-01-18.wav\n",
            "03-01-06-01-02-01-18.wav\n",
            "03-01-06-02-01-02-18.wav\n",
            "03-01-01-01-02-01-18.wav\n",
            "03-01-06-01-02-02-18.wav\n",
            "03-01-06-01-01-02-18.wav\n",
            "03-01-01-01-01-02-18.wav\n",
            "03-01-02-02-01-01-18.wav\n",
            "03-01-05-01-02-02-18.wav\n",
            "03-01-08-02-02-01-18.wav\n",
            "03-01-05-02-02-02-18.wav\n",
            "03-01-04-02-02-02-18.wav\n",
            "03-01-04-02-02-01-18.wav\n",
            "03-01-05-01-01-02-18.wav\n",
            "03-01-03-02-01-01-18.wav\n",
            "03-01-05-01-02-01-18.wav\n",
            "03-01-07-01-01-02-18.wav\n",
            "03-01-04-01-02-01-18.wav\n",
            "03-01-03-02-02-01-18.wav\n",
            "03-01-02-02-01-02-18.wav\n",
            "03-01-01-01-02-02-18.wav\n",
            "03-01-05-01-01-01-18.wav\n",
            "03-01-02-02-02-01-18.wav\n",
            "03-01-03-01-02-02-18.wav\n",
            "03-01-06-01-01-01-18.wav\n",
            "03-01-01-01-01-01-18.wav\n",
            "03-01-04-02-01-02-18.wav\n",
            "03-01-07-01-01-01-18.wav\n",
            "03-01-07-02-02-02-18.wav\n",
            "03-01-02-01-02-01-18.wav\n",
            "03-01-07-01-02-01-18.wav\n",
            "03-01-05-02-01-01-18.wav\n",
            "03-01-04-01-02-02-18.wav\n",
            "03-01-08-02-01-02-18.wav\n",
            "03-01-02-01-01-01-18.wav\n",
            "03-01-05-02-02-01-18.wav\n",
            "03-01-03-01-01-02-18.wav\n",
            "03-01-08-02-01-01-18.wav\n",
            "03-01-07-02-01-01-18.wav\n",
            "03-01-02-01-02-02-18.wav\n",
            "03-01-08-01-01-02-18.wav\n",
            "03-01-06-02-02-01-18.wav\n",
            "03-01-07-02-01-02-18.wav\n",
            "03-01-08-01-02-02-18.wav\n",
            "03-01-06-02-02-02-18.wav\n",
            "03-01-07-01-02-02-18.wav\n",
            "03-01-03-01-01-01-18.wav\n",
            "03-01-04-01-01-02-18.wav\n",
            "03-01-08-02-02-02-18.wav\n",
            "03-01-03-01-02-01-18.wav\n",
            "03-01-02-01-01-02-18.wav\n",
            "03-01-01-01-01-01-19.wav\n",
            "03-01-01-01-01-02-19.wav\n",
            "03-01-02-02-01-02-19.wav\n",
            "03-01-07-01-02-02-19.wav\n",
            "03-01-01-01-02-01-19.wav\n",
            "03-01-08-02-02-01-19.wav\n",
            "03-01-07-02-01-02-19.wav\n",
            "03-01-08-01-02-01-19.wav\n",
            "03-01-06-02-02-02-19.wav\n",
            "03-01-07-01-02-01-19.wav\n",
            "03-01-07-02-02-02-19.wav\n",
            "03-01-02-01-01-01-19.wav\n",
            "03-01-08-01-02-02-19.wav\n",
            "03-01-05-02-01-01-19.wav\n",
            "03-01-02-01-02-02-19.wav\n",
            "03-01-02-02-02-01-19.wav\n",
            "03-01-06-01-01-02-19.wav\n",
            "03-01-03-02-01-02-19.wav\n",
            "03-01-03-02-01-01-19.wav\n",
            "03-01-02-02-02-02-19.wav\n",
            "03-01-04-02-01-01-19.wav\n",
            "03-01-08-02-02-02-19.wav\n",
            "03-01-03-01-02-02-19.wav\n",
            "03-01-06-01-02-02-19.wav\n",
            "03-01-04-01-01-01-19.wav\n",
            "03-01-06-02-01-02-19.wav\n",
            "03-01-03-01-02-01-19.wav\n",
            "03-01-08-02-01-01-19.wav\n",
            "03-01-03-01-01-02-19.wav\n",
            "03-01-07-01-01-01-19.wav\n",
            "03-01-04-02-02-01-19.wav\n",
            "03-01-06-02-02-01-19.wav\n",
            "03-01-02-01-02-01-19.wav\n",
            "03-01-03-02-02-02-19.wav\n",
            "03-01-08-01-01-01-19.wav\n",
            "03-01-05-01-01-02-19.wav\n",
            "03-01-06-01-02-01-19.wav\n",
            "03-01-03-01-01-01-19.wav\n",
            "03-01-05-02-01-02-19.wav\n",
            "03-01-06-01-01-01-19.wav\n",
            "03-01-02-01-01-02-19.wav\n",
            "03-01-06-02-01-01-19.wav\n",
            "03-01-03-02-02-01-19.wav\n",
            "03-01-01-01-02-02-19.wav\n",
            "03-01-07-02-02-01-19.wav\n",
            "03-01-04-01-02-01-19.wav\n",
            "03-01-04-01-02-02-19.wav\n",
            "03-01-02-02-01-01-19.wav\n",
            "03-01-05-01-01-01-19.wav\n",
            "03-01-07-01-01-02-19.wav\n",
            "03-01-08-02-01-02-19.wav\n",
            "03-01-04-02-01-02-19.wav\n",
            "03-01-04-02-02-02-19.wav\n",
            "03-01-04-01-01-02-19.wav\n",
            "03-01-05-02-02-01-19.wav\n",
            "03-01-05-01-02-01-19.wav\n",
            "03-01-08-01-01-02-19.wav\n",
            "03-01-05-02-02-02-19.wav\n",
            "03-01-05-01-02-02-19.wav\n",
            "03-01-07-02-01-01-19.wav\n",
            "03-01-04-02-02-01-20.wav\n",
            "03-01-02-02-02-02-20.wav\n",
            "03-01-08-01-01-02-20.wav\n",
            "03-01-05-02-01-02-20.wav\n",
            "03-01-08-02-02-02-20.wav\n",
            "03-01-07-02-01-01-20.wav\n",
            "03-01-01-01-01-01-20.wav\n",
            "03-01-07-02-02-01-20.wav\n",
            "03-01-07-02-02-02-20.wav\n",
            "03-01-02-01-02-01-20.wav\n",
            "03-01-07-01-01-01-20.wav\n",
            "03-01-04-02-02-02-20.wav\n",
            "03-01-07-01-02-01-20.wav\n",
            "03-01-08-02-01-01-20.wav\n",
            "03-01-02-01-01-01-20.wav\n",
            "03-01-01-01-02-01-20.wav\n",
            "03-01-04-01-01-02-20.wav\n",
            "03-01-05-02-02-01-20.wav\n",
            "03-01-05-01-02-02-20.wav\n",
            "03-01-08-01-02-02-20.wav\n",
            "03-01-03-01-01-02-20.wav\n",
            "03-01-03-01-02-01-20.wav\n",
            "03-01-03-02-02-01-20.wav\n",
            "03-01-06-01-02-02-20.wav\n",
            "03-01-08-01-02-01-20.wav\n",
            "03-01-02-01-02-02-20.wav\n",
            "03-01-06-02-01-01-20.wav\n",
            "03-01-06-01-02-01-20.wav\n",
            "03-01-07-01-02-02-20.wav\n",
            "03-01-06-01-01-01-20.wav\n",
            "03-01-05-01-01-02-20.wav\n",
            "03-01-02-02-01-02-20.wav\n",
            "03-01-08-02-02-01-20.wav\n",
            "03-01-05-02-01-01-20.wav\n",
            "03-01-04-01-02-01-20.wav\n",
            "03-01-08-02-01-02-20.wav\n",
            "03-01-03-02-01-02-20.wav\n",
            "03-01-02-02-01-01-20.wav\n",
            "03-01-07-01-01-02-20.wav\n",
            "03-01-01-01-02-02-20.wav\n",
            "03-01-07-02-01-02-20.wav\n",
            "03-01-03-02-01-01-20.wav\n",
            "03-01-06-02-02-01-20.wav\n",
            "03-01-05-01-01-01-20.wav\n",
            "03-01-04-02-01-02-20.wav\n",
            "03-01-08-01-01-01-20.wav\n",
            "03-01-03-01-01-01-20.wav\n",
            "03-01-04-02-01-01-20.wav\n",
            "03-01-06-02-01-02-20.wav\n",
            "03-01-03-02-02-02-20.wav\n",
            "03-01-01-01-01-02-20.wav\n",
            "03-01-06-02-02-02-20.wav\n",
            "03-01-02-01-01-02-20.wav\n",
            "03-01-05-02-02-02-20.wav\n",
            "03-01-04-01-02-02-20.wav\n",
            "03-01-04-01-01-01-20.wav\n",
            "03-01-02-02-02-01-20.wav\n",
            "03-01-03-01-02-02-20.wav\n",
            "03-01-05-01-02-01-20.wav\n",
            "03-01-06-01-01-02-20.wav\n",
            "03-01-07-01-02-01-21.wav\n",
            "03-01-03-01-02-01-21.wav\n",
            "03-01-06-02-02-01-21.wav\n",
            "03-01-08-02-02-02-21.wav\n",
            "03-01-02-01-01-01-21.wav\n",
            "03-01-05-01-01-02-21.wav\n",
            "03-01-05-01-02-01-21.wav\n",
            "03-01-06-01-01-02-21.wav\n",
            "03-01-08-01-01-01-21.wav\n",
            "03-01-02-02-01-02-21.wav\n",
            "03-01-04-01-02-02-21.wav\n",
            "03-01-03-02-02-01-21.wav\n",
            "03-01-03-02-01-01-21.wav\n",
            "03-01-02-02-02-02-21.wav\n",
            "03-01-06-01-02-01-21.wav\n",
            "03-01-02-02-01-01-21.wav\n",
            "03-01-04-01-02-01-21.wav\n",
            "03-01-01-01-01-01-21.wav\n",
            "03-01-04-01-01-01-21.wav\n",
            "03-01-03-01-02-02-21.wav\n",
            "03-01-02-01-02-02-21.wav\n",
            "03-01-08-02-02-01-21.wav\n",
            "03-01-04-02-02-02-21.wav\n",
            "03-01-03-01-01-02-21.wav\n",
            "03-01-05-02-01-02-21.wav\n",
            "03-01-03-01-01-01-21.wav\n",
            "03-01-08-01-01-02-21.wav\n",
            "03-01-08-02-01-02-21.wav\n",
            "03-01-04-02-01-02-21.wav\n",
            "03-01-06-02-02-02-21.wav\n",
            "03-01-02-01-01-02-21.wav\n",
            "03-01-05-01-02-02-21.wav\n",
            "03-01-08-01-02-02-21.wav\n",
            "03-01-04-02-02-01-21.wav\n",
            "03-01-08-02-01-01-21.wav\n",
            "03-01-08-01-02-01-21.wav\n",
            "03-01-07-02-01-01-21.wav\n",
            "03-01-07-02-01-02-21.wav\n",
            "03-01-02-02-02-01-21.wav\n",
            "03-01-05-02-02-01-21.wav\n",
            "03-01-02-01-02-01-21.wav\n",
            "03-01-04-01-01-02-21.wav\n",
            "03-01-05-02-02-02-21.wav\n",
            "03-01-07-02-02-02-21.wav\n",
            "03-01-03-02-01-02-21.wav\n",
            "03-01-04-02-01-01-21.wav\n",
            "03-01-01-01-02-01-21.wav\n",
            "03-01-06-01-02-02-21.wav\n",
            "03-01-07-02-02-01-21.wav\n",
            "03-01-05-01-01-01-21.wav\n",
            "03-01-07-01-02-02-21.wav\n",
            "03-01-06-02-01-02-21.wav\n",
            "03-01-03-02-02-02-21.wav\n",
            "03-01-01-01-02-02-21.wav\n",
            "03-01-01-01-01-02-21.wav\n",
            "03-01-06-01-01-01-21.wav\n",
            "03-01-07-01-01-02-21.wav\n",
            "03-01-07-01-01-01-21.wav\n",
            "03-01-06-02-01-01-21.wav\n",
            "03-01-05-02-01-01-21.wav\n",
            "03-01-03-02-01-01-22.wav\n",
            "03-01-02-02-02-02-22.wav\n",
            "03-01-02-02-01-01-22.wav\n",
            "03-01-01-01-02-02-22.wav\n",
            "03-01-04-02-02-01-22.wav\n",
            "03-01-04-02-01-02-22.wav\n",
            "03-01-03-02-02-01-22.wav\n",
            "03-01-01-01-02-01-22.wav\n",
            "03-01-03-01-02-01-22.wav\n",
            "03-01-04-01-01-01-22.wav\n",
            "03-01-03-01-02-02-22.wav\n",
            "03-01-01-01-01-01-22.wav\n",
            "03-01-03-01-01-02-22.wav\n",
            "03-01-02-02-01-02-22.wav\n",
            "03-01-03-01-01-01-22.wav\n",
            "03-01-02-01-01-02-22.wav\n",
            "03-01-02-02-02-01-22.wav\n",
            "03-01-04-02-02-02-22.wav\n",
            "03-01-02-01-02-01-22.wav\n",
            "03-01-03-02-02-02-22.wav\n",
            "03-01-04-01-02-02-22.wav\n",
            "03-01-04-01-01-02-22.wav\n",
            "03-01-04-01-02-01-22.wav\n",
            "03-01-02-01-02-02-22.wav\n",
            "03-01-04-02-01-01-22.wav\n",
            "03-01-03-02-01-02-22.wav\n",
            "03-01-01-01-01-02-22.wav\n",
            "03-01-02-01-01-01-22.wav\n",
            "03-01-06-02-01-01-22.wav\n",
            "03-01-08-02-01-01-22.wav\n",
            "03-01-05-02-02-02-22.wav\n",
            "03-01-07-02-02-01-22.wav\n",
            "03-01-07-01-01-01-22.wav\n",
            "03-01-08-02-02-01-22.wav\n",
            "03-01-07-02-01-01-22.wav\n",
            "03-01-08-01-01-01-22.wav\n",
            "03-01-08-02-01-02-22.wav\n",
            "03-01-05-02-01-02-22.wav\n",
            "03-01-06-01-02-02-22.wav\n",
            "03-01-08-02-02-02-22.wav\n",
            "03-01-05-01-02-01-22.wav\n",
            "03-01-07-02-02-02-22.wav\n",
            "03-01-07-01-02-02-22.wav\n",
            "03-01-08-01-02-01-22.wav\n",
            "03-01-05-01-01-01-22.wav\n",
            "03-01-06-02-01-02-22.wav\n",
            "03-01-06-02-02-01-22.wav\n",
            "03-01-07-01-01-02-22.wav\n",
            "03-01-06-01-01-01-22.wav\n",
            "03-01-05-02-02-01-22.wav\n",
            "03-01-08-01-01-02-22.wav\n",
            "03-01-07-02-01-02-22.wav\n",
            "03-01-07-01-02-01-22.wav\n",
            "03-01-05-01-02-02-22.wav\n",
            "03-01-05-02-01-01-22.wav\n",
            "03-01-05-01-01-02-22.wav\n",
            "03-01-06-01-02-01-22.wav\n",
            "03-01-06-02-02-02-22.wav\n",
            "03-01-08-01-02-02-22.wav\n",
            "03-01-06-01-01-02-22.wav\n",
            "03-01-05-02-01-02-23.wav\n",
            "03-01-02-01-01-01-23.wav\n",
            "03-01-02-01-02-02-23.wav\n",
            "03-01-08-02-01-02-23.wav\n",
            "03-01-05-02-01-01-23.wav\n",
            "03-01-04-01-02-02-23.wav\n",
            "03-01-03-01-02-01-23.wav\n",
            "03-01-07-02-01-02-23.wav\n",
            "03-01-06-02-02-02-23.wav\n",
            "03-01-02-01-02-01-23.wav\n",
            "03-01-03-02-01-01-23.wav\n",
            "03-01-06-01-01-01-23.wav\n",
            "03-01-03-02-01-02-23.wav\n",
            "03-01-02-02-01-02-23.wav\n",
            "03-01-08-02-02-02-23.wav\n",
            "03-01-06-01-02-02-23.wav\n",
            "03-01-08-02-02-01-23.wav\n",
            "03-01-07-01-02-01-23.wav\n",
            "03-01-08-01-01-01-23.wav\n",
            "03-01-05-02-02-01-23.wav\n",
            "03-01-07-02-02-02-23.wav\n",
            "03-01-02-02-02-02-23.wav\n",
            "03-01-07-02-02-01-23.wav\n",
            "03-01-01-01-01-01-23.wav\n",
            "03-01-04-02-02-01-23.wav\n",
            "03-01-05-01-02-01-23.wav\n",
            "03-01-08-02-01-01-23.wav\n",
            "03-01-08-01-01-02-23.wav\n",
            "03-01-05-02-02-02-23.wav\n",
            "03-01-03-01-01-02-23.wav\n",
            "03-01-03-02-02-02-23.wav\n",
            "03-01-01-01-01-02-23.wav\n",
            "03-01-01-01-02-02-23.wav\n",
            "03-01-03-01-01-01-23.wav\n",
            "03-01-06-01-02-01-23.wav\n",
            "03-01-02-02-02-01-23.wav\n",
            "03-01-06-02-01-01-23.wav\n",
            "03-01-04-02-01-01-23.wav\n",
            "03-01-05-01-02-02-23.wav\n",
            "03-01-01-01-02-01-23.wav\n",
            "03-01-07-02-01-01-23.wav\n",
            "03-01-02-02-01-01-23.wav\n",
            "03-01-02-01-01-02-23.wav\n",
            "03-01-07-01-01-01-23.wav\n",
            "03-01-05-01-01-01-23.wav\n",
            "03-01-08-01-02-02-23.wav\n",
            "03-01-06-02-02-01-23.wav\n",
            "03-01-03-01-02-02-23.wav\n",
            "03-01-06-02-01-02-23.wav\n",
            "03-01-03-02-02-01-23.wav\n",
            "03-01-04-01-02-01-23.wav\n",
            "03-01-07-01-01-02-23.wav\n",
            "03-01-04-01-01-01-23.wav\n",
            "03-01-05-01-01-02-23.wav\n",
            "03-01-04-01-01-02-23.wav\n",
            "03-01-06-01-01-02-23.wav\n",
            "03-01-04-02-02-02-23.wav\n",
            "03-01-07-01-02-02-23.wav\n",
            "03-01-08-01-02-01-23.wav\n",
            "03-01-04-02-01-02-23.wav\n",
            "03-01-07-02-01-02-24.wav\n",
            "03-01-04-01-01-01-24.wav\n",
            "03-01-03-01-01-02-24.wav\n",
            "03-01-08-01-01-02-24.wav\n",
            "03-01-05-02-01-02-24.wav\n",
            "03-01-05-02-02-02-24.wav\n",
            "03-01-03-02-02-02-24.wav\n",
            "03-01-05-02-01-01-24.wav\n",
            "03-01-03-02-02-01-24.wav\n",
            "03-01-05-01-02-02-24.wav\n",
            "03-01-07-01-01-02-24.wav\n",
            "03-01-08-01-01-01-24.wav\n",
            "03-01-04-01-01-02-24.wav\n",
            "03-01-05-01-01-01-24.wav\n",
            "03-01-06-01-02-01-24.wav\n",
            "03-01-08-02-02-01-24.wav\n",
            "03-01-03-02-01-02-24.wav\n",
            "03-01-07-02-02-01-24.wav\n",
            "03-01-04-02-01-02-24.wav\n",
            "03-01-06-02-01-02-24.wav\n",
            "03-01-05-02-02-01-24.wav\n",
            "03-01-07-02-01-01-24.wav\n",
            "03-01-03-01-02-01-24.wav\n",
            "03-01-03-01-02-02-24.wav\n",
            "03-01-08-01-02-02-24.wav\n",
            "03-01-06-01-01-01-24.wav\n",
            "03-01-08-02-02-02-24.wav\n",
            "03-01-08-02-01-02-24.wav\n",
            "03-01-02-02-02-01-24.wav\n",
            "03-01-07-01-02-01-24.wav\n",
            "03-01-03-01-01-01-24.wav\n",
            "03-01-03-02-01-01-24.wav\n",
            "03-01-02-02-01-02-24.wav\n",
            "03-01-06-02-01-01-24.wav\n",
            "03-01-05-01-02-01-24.wav\n",
            "03-01-06-02-02-02-24.wav\n",
            "03-01-08-01-02-01-24.wav\n",
            "03-01-02-01-01-01-24.wav\n",
            "03-01-06-01-02-02-24.wav\n",
            "03-01-06-01-01-02-24.wav\n",
            "03-01-02-01-02-01-24.wav\n",
            "03-01-05-01-01-02-24.wav\n",
            "03-01-04-01-02-02-24.wav\n",
            "03-01-01-01-02-02-24.wav\n",
            "03-01-04-02-02-02-24.wav\n",
            "03-01-02-01-02-02-24.wav\n",
            "03-01-08-02-01-01-24.wav\n",
            "03-01-07-02-02-02-24.wav\n",
            "03-01-01-01-01-01-24.wav\n",
            "03-01-02-02-01-01-24.wav\n",
            "03-01-02-01-01-02-24.wav\n",
            "03-01-01-01-02-01-24.wav\n",
            "03-01-01-01-01-02-24.wav\n",
            "03-01-04-01-02-01-24.wav\n",
            "03-01-02-02-02-02-24.wav\n",
            "03-01-06-02-02-01-24.wav\n",
            "03-01-07-01-02-02-24.wav\n",
            "03-01-07-01-01-01-24.wav\n",
            "03-01-04-02-02-01-24.wav\n",
            "03-01-04-02-01-01-24.wav\n",
            "[+] Number of training samples: 504\n",
            "[+] Number of testing samples: 168\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = load_data(test_size=0.25)\n",
        "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
        "print(\"[+] Number of testing samples:\", X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO3OzGWt22Sq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_train = np.asarray(X_train)\n",
        "y_train= np.asarray(y_train)\n",
        "X_test=np.array(X_test)\n",
        "y_test=np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_HrHWFo3KFH",
        "outputId": "83736d49-8f0e-403a-825b-1f25611abe2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((504, 180), (504,), (168, 180), (168,))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuGn3O113iVS"
      },
      "outputs": [],
      "source": [
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmqNzFs85Ck6",
        "outputId": "ca0c3c7b-06a0-41a1-fb90-06fd8430050a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((504, 180, 1), (168, 180, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "x_traincnn.shape,x_testcnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxP30CnnoW2L",
        "outputId": "556cfe9f-2f7f-4e9b-cc06-d8717b65063c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Number of training samples: 504\n",
            "[+] Number of testing samples: 168\n",
            "[+] Number of features: 180\n"
          ]
        }
      ],
      "source": [
        "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
        "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
        "print(\"[+] Number of features:\", X_train.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCVruTprgsNK"
      },
      "source": [
        "# ***FIRST MODEL***\n",
        "\n",
        "Two Relu and one Softmax\n",
        "\n",
        "Sparse Categorial CrossEntropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhBOW8Rk5VKt"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))        #1\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv1D(128, 5,padding='same',))                           #2\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8))                                                 #3\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5nm0kqP5hV1",
        "outputId": "2d17d74a-04f3-4766-f447-a8992099d94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_20 (Conv1D)          (None, 180, 128)          768       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 180, 128)          0         \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 180, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 22, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 22, 128)           82048     \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 22, 128)           0         \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 22, 128)           0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 22536     \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 105,352\n",
            "Trainable params: 105,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-fAEnOR5nvH"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6opFz235tL0",
        "outputId": "ee643f7d-0ae9-4b41-9046-6a6424940719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 1s 12ms/step - loss: 3.9304 - accuracy: 0.2282 - val_loss: 1.6614 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.6673 - accuracy: 0.2877 - val_loss: 1.2981 - val_accuracy: 0.3750\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4248 - accuracy: 0.3234 - val_loss: 1.5708 - val_accuracy: 0.2381\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4349 - accuracy: 0.3254 - val_loss: 1.4823 - val_accuracy: 0.3512\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.3001 - accuracy: 0.3254 - val_loss: 1.7897 - val_accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.0880 - accuracy: 0.3492 - val_loss: 1.1905 - val_accuracy: 0.4286\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.1940 - accuracy: 0.3373 - val_loss: 1.6466 - val_accuracy: 0.3512\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.0760 - accuracy: 0.3373 - val_loss: 1.3016 - val_accuracy: 0.4167\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.0575 - accuracy: 0.3552 - val_loss: 1.3031 - val_accuracy: 0.4940\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.9178 - accuracy: 0.3730 - val_loss: 1.4105 - val_accuracy: 0.3690\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.0211 - accuracy: 0.3631 - val_loss: 1.3097 - val_accuracy: 0.3512\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.9435 - accuracy: 0.3492 - val_loss: 1.2475 - val_accuracy: 0.4048\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.9020 - accuracy: 0.3611 - val_loss: 1.1487 - val_accuracy: 0.4524\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6534 - accuracy: 0.3889 - val_loss: 1.3874 - val_accuracy: 0.3810\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.8087 - accuracy: 0.3611 - val_loss: 1.2391 - val_accuracy: 0.5179\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.7840 - accuracy: 0.3671 - val_loss: 1.0426 - val_accuracy: 0.5476\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.7574 - accuracy: 0.3770 - val_loss: 1.1882 - val_accuracy: 0.4940\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6063 - accuracy: 0.3988 - val_loss: 1.1747 - val_accuracy: 0.4821\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6149 - accuracy: 0.4385 - val_loss: 1.2089 - val_accuracy: 0.4464\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6045 - accuracy: 0.4028 - val_loss: 1.3551 - val_accuracy: 0.4167\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.7233 - accuracy: 0.3988 - val_loss: 1.3360 - val_accuracy: 0.4048\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.5279 - accuracy: 0.4187 - val_loss: 1.0304 - val_accuracy: 0.5238\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6458 - accuracy: 0.4028 - val_loss: 1.1910 - val_accuracy: 0.5179\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.5788 - accuracy: 0.4028 - val_loss: 1.1078 - val_accuracy: 0.4762\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4159 - accuracy: 0.4325 - val_loss: 1.1678 - val_accuracy: 0.4405\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5284 - accuracy: 0.3909 - val_loss: 1.5218 - val_accuracy: 0.4107\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4309 - accuracy: 0.4425 - val_loss: 1.0311 - val_accuracy: 0.5595\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4317 - accuracy: 0.4345 - val_loss: 1.3334 - val_accuracy: 0.4643\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4084 - accuracy: 0.4286 - val_loss: 1.0854 - val_accuracy: 0.4405\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3631 - accuracy: 0.4583 - val_loss: 1.3372 - val_accuracy: 0.4286\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4822 - accuracy: 0.4167 - val_loss: 1.0545 - val_accuracy: 0.5179\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3042 - accuracy: 0.4643 - val_loss: 1.1811 - val_accuracy: 0.4464\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3552 - accuracy: 0.4167 - val_loss: 0.9828 - val_accuracy: 0.5238\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3673 - accuracy: 0.4563 - val_loss: 1.1050 - val_accuracy: 0.4881\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3348 - accuracy: 0.4425 - val_loss: 1.2118 - val_accuracy: 0.5179\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3265 - accuracy: 0.4464 - val_loss: 1.0635 - val_accuracy: 0.4762\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3607 - accuracy: 0.4286 - val_loss: 0.9913 - val_accuracy: 0.5655\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3049 - accuracy: 0.4484 - val_loss: 1.0212 - val_accuracy: 0.5238\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3077 - accuracy: 0.4345 - val_loss: 1.2588 - val_accuracy: 0.3988\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.2508 - accuracy: 0.4563 - val_loss: 1.0525 - val_accuracy: 0.5119\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1982 - accuracy: 0.4901 - val_loss: 1.0059 - val_accuracy: 0.5595\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.2193 - accuracy: 0.4563 - val_loss: 1.0527 - val_accuracy: 0.4762\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.2317 - accuracy: 0.4603 - val_loss: 1.0464 - val_accuracy: 0.4524\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.2138 - accuracy: 0.4563 - val_loss: 1.0629 - val_accuracy: 0.5060\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1595 - accuracy: 0.4643 - val_loss: 1.1224 - val_accuracy: 0.4702\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2206 - accuracy: 0.4643 - val_loss: 1.0027 - val_accuracy: 0.5119\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1466 - accuracy: 0.4683 - val_loss: 0.9886 - val_accuracy: 0.5357\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1819 - accuracy: 0.4663 - val_loss: 1.0065 - val_accuracy: 0.4940\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1688 - accuracy: 0.4742 - val_loss: 1.4879 - val_accuracy: 0.4048\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1757 - accuracy: 0.4663 - val_loss: 1.0621 - val_accuracy: 0.4940\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1644 - accuracy: 0.4782 - val_loss: 1.1286 - val_accuracy: 0.4345\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1146 - accuracy: 0.5079 - val_loss: 1.1275 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1443 - accuracy: 0.4821 - val_loss: 0.9807 - val_accuracy: 0.5417\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1239 - accuracy: 0.4841 - val_loss: 1.2432 - val_accuracy: 0.4643\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0856 - accuracy: 0.4940 - val_loss: 0.9896 - val_accuracy: 0.5298\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1147 - accuracy: 0.4643 - val_loss: 1.0636 - val_accuracy: 0.4940\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0933 - accuracy: 0.5040 - val_loss: 0.9433 - val_accuracy: 0.5774\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0474 - accuracy: 0.5159 - val_loss: 1.0499 - val_accuracy: 0.4464\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0825 - accuracy: 0.5000 - val_loss: 0.9712 - val_accuracy: 0.5476\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0702 - accuracy: 0.5397 - val_loss: 0.9561 - val_accuracy: 0.6071\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0952 - accuracy: 0.4861 - val_loss: 1.0235 - val_accuracy: 0.5298\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0482 - accuracy: 0.5218 - val_loss: 0.9802 - val_accuracy: 0.5119\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0783 - accuracy: 0.4841 - val_loss: 0.9862 - val_accuracy: 0.5595\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0907 - accuracy: 0.5020 - val_loss: 1.0002 - val_accuracy: 0.5060\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0416 - accuracy: 0.5258 - val_loss: 0.9536 - val_accuracy: 0.5714\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0044 - accuracy: 0.5635 - val_loss: 1.0439 - val_accuracy: 0.5060\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0571 - accuracy: 0.5258 - val_loss: 1.0276 - val_accuracy: 0.4643\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0504 - accuracy: 0.5179 - val_loss: 0.9746 - val_accuracy: 0.5357\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0473 - accuracy: 0.5159 - val_loss: 0.9456 - val_accuracy: 0.5714\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0020 - accuracy: 0.5496 - val_loss: 0.9688 - val_accuracy: 0.5595\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0167 - accuracy: 0.5456 - val_loss: 0.9614 - val_accuracy: 0.5655\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0066 - accuracy: 0.5456 - val_loss: 1.0780 - val_accuracy: 0.4881\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0105 - accuracy: 0.5417 - val_loss: 0.9657 - val_accuracy: 0.5774\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0279 - accuracy: 0.5456 - val_loss: 0.9577 - val_accuracy: 0.5595\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9780 - accuracy: 0.5496 - val_loss: 0.9485 - val_accuracy: 0.5417\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9942 - accuracy: 0.5437 - val_loss: 1.0996 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0246 - accuracy: 0.5238 - val_loss: 1.1475 - val_accuracy: 0.4226\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0317 - accuracy: 0.5198 - val_loss: 0.9279 - val_accuracy: 0.5952\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9735 - accuracy: 0.5595 - val_loss: 0.9615 - val_accuracy: 0.5476\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9843 - accuracy: 0.5317 - val_loss: 0.9263 - val_accuracy: 0.5774\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0192 - accuracy: 0.5278 - val_loss: 0.9766 - val_accuracy: 0.5060\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.0063 - accuracy: 0.5317 - val_loss: 1.0264 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9694 - accuracy: 0.5655 - val_loss: 0.9444 - val_accuracy: 0.5536\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0074 - accuracy: 0.5139 - val_loss: 0.9195 - val_accuracy: 0.6190\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9992 - accuracy: 0.5218 - val_loss: 0.9941 - val_accuracy: 0.5238\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9829 - accuracy: 0.5536 - val_loss: 0.9459 - val_accuracy: 0.5595\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9803 - accuracy: 0.5496 - val_loss: 0.9572 - val_accuracy: 0.5536\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9493 - accuracy: 0.5675 - val_loss: 0.9334 - val_accuracy: 0.5774\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9371 - accuracy: 0.5595 - val_loss: 1.0040 - val_accuracy: 0.4940\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9449 - accuracy: 0.5714 - val_loss: 0.9343 - val_accuracy: 0.5833\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9878 - accuracy: 0.5437 - val_loss: 0.9128 - val_accuracy: 0.5714\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9525 - accuracy: 0.5556 - val_loss: 0.9424 - val_accuracy: 0.5714\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9615 - accuracy: 0.5575 - val_loss: 0.9508 - val_accuracy: 0.5417\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9611 - accuracy: 0.5595 - val_loss: 0.9253 - val_accuracy: 0.5833\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9429 - accuracy: 0.5833 - val_loss: 1.0373 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9371 - accuracy: 0.5655 - val_loss: 0.9101 - val_accuracy: 0.5774\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9453 - accuracy: 0.5754 - val_loss: 0.9319 - val_accuracy: 0.6190\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9268 - accuracy: 0.5754 - val_loss: 0.9194 - val_accuracy: 0.6190\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9480 - accuracy: 0.5655 - val_loss: 0.9003 - val_accuracy: 0.6250\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9519 - accuracy: 0.5734 - val_loss: 0.9143 - val_accuracy: 0.5714\n"
          ]
        }
      ],
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=25, epochs=100, validation_data=(x_testcnn, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRBYh-bMHucX"
      },
      "outputs": [],
      "source": [
        "em=['happy','sad','neutral','angry']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8YDjqpINC81",
        "outputId": "3f5aced9-8fa4-4bca-cf6d-111559b80384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy', 'sad', 'neutral', 'angry']\n"
          ]
        }
      ],
      "source": [
        "predict_x=model.predict(x_testcnn)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "n=classes_x[1]\n",
        "print(em)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxJc4kIaD9IK",
        "outputId": "fe3106be-b694-4159-db5b-747d717a118c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9143 - accuracy: 0.5714\n",
            "Restored model, accuracy: 57.14%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rOwYX3-j_jO"
      },
      "source": [
        "#  Testing 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVanJ86-FhwS",
        "outputId": "7b5236bc-c46e-490a-93d7-9d17422a919b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result : happy\n"
          ]
        }
      ],
      "source": [
        "filename = \"/content/drive/My Drive/DataSets/audio_speech_actors_01-24/Actor_01/03-01-08-01-01-01-01.wav\"\n",
        "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
        "f=np.expand_dims(features,axis=2)\n",
        "predict_x=model.predict(f)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "result=int(classes_x)-1\n",
        "print(\"result :\",em[result])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo2NA08o5jCJ",
        "outputId": "0dac1953-6a34-4733-bf1a-0738bf40644e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5714285714285714\n",
            "F1 score: 0.5813718720199927\n",
            "Recall: 0.5714285714285714\n",
            "Precision: 0.6220472524849538\n",
            "\n",
            " classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.65      0.62        52\n",
            "         1.0       0.47      0.52      0.49        44\n",
            "         3.0       0.37      0.55      0.44        20\n",
            "         4.0       0.88      0.54      0.67        52\n",
            "\n",
            "    accuracy                           0.57       168\n",
            "   macro avg       0.58      0.57      0.56       168\n",
            "weighted avg       0.62      0.57      0.58       168\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[34 11  4  3]\n",
            " [ 7 23 13  1]\n",
            " [ 0  9 11  0]\n",
            " [16  6  2 28]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score\n",
        "predict_x=model.predict(x_testcnn)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "#print(classification_report(y_test,classes_x))\n",
        "#print(confusion_matrix(y_test,classes_x))\n",
        "print ('Accuracy:', accuracy_score(y_test, classes_x))\n",
        "print ('F1 score:', f1_score(y_test, classes_x,average='weighted'))\n",
        "print ('Recall:', recall_score(y_test, classes_x,average='weighted'))\n",
        "print ('Precision:', precision_score(y_test, classes_x,average='weighted'))\n",
        "print ('\\n classification report:\\n', classification_report(y_test, classes_x))\n",
        "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, classes_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvWjQQkvyaNM",
        "outputId": "ca248bd2-b8a6-4b72-a87c-944fc8a667cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP 23\n",
            "FP 26\n",
            "TN 34\n",
            "FP 23\n"
          ]
        }
      ],
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)\n",
        "res = perf_measure(y_test, classes_x)\n",
        "print(\"TP\",res[0])\n",
        "print(\"FP\",res[1])\n",
        "print(\"TN\",res[2])\n",
        "print(\"FP\",res[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "2PsKTX9lmDmP",
        "outputId": "ee809ac8-9a68-4d9a-a12d-639c687789f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "cm1 = pd.DataFrame(confusion_matrix(y_test, classes_x))\n",
        "plt.figure(figsize = (10, 8))\n",
        "sns.heatmap(cm1, annot = True, cbar = False, fmt = 'g')\n",
        "plt.ylabel('Actual values')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1vlkqDPlA8A"
      },
      "source": [
        "# ***SECOND MODEL***\n",
        "\n",
        "Three Relu and one Softmax (Dropout = 0.25)\n",
        "\n",
        "Sparse categorial Crossentropy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQR38pmCSaNU"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "um = Sequential()\n",
        "\n",
        "um.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
        "um.add(Activation('relu'))\n",
        "um.add(Dropout(0.25))\n",
        "um.add(MaxPooling1D(pool_size=(8)))\n",
        "\n",
        "um.add(Conv1D(128, 5,padding='same',))                  #2\n",
        "um.add(Activation('relu'))\n",
        "um.add(MaxPooling1D(pool_size=(8)))\n",
        "um.add(Dropout(0.25))\n",
        "\n",
        "um.add(Conv1D(128, 5,padding='same',))                  #3\n",
        "um.add(Activation('relu'))\n",
        "um.add(Dropout(0.25))\n",
        "\n",
        "um.add(Flatten())\n",
        "um.add(Dense(8))                                        #4                      \n",
        "um.add(Activation('softmax'))\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.00005,epsilon=None,rho=0.9,decay=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfXWyKwKbNfB",
        "outputId": "6e5dec3a-16e1-402c-99cc-90df5c1b5bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_22 (Conv1D)          (None, 180, 128)          768       \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 180, 128)          0         \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 180, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 22, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 22, 128)           82048     \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 22, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 2, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 2056      \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 166,920\n",
            "Trainable params: 166,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "um.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBIGulu3bSaj"
      },
      "outputs": [],
      "source": [
        "um.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XiAWqd1bg5M",
        "outputId": "1a9d5156-2ab4-4529-8432-a37c941edb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 1s 13ms/step - loss: 9.9807 - accuracy: 0.1825 - val_loss: 1.7114 - val_accuracy: 0.3214\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.8567 - accuracy: 0.2937 - val_loss: 2.2266 - val_accuracy: 0.2976\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.5110 - accuracy: 0.2460 - val_loss: 1.4010 - val_accuracy: 0.3274\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.6552 - accuracy: 0.3075 - val_loss: 1.7652 - val_accuracy: 0.2381\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.3529 - accuracy: 0.2937 - val_loss: 1.5359 - val_accuracy: 0.4048\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.9154 - accuracy: 0.2976 - val_loss: 1.3521 - val_accuracy: 0.3631\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.5932 - accuracy: 0.3075 - val_loss: 2.0122 - val_accuracy: 0.3393\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.0659 - accuracy: 0.3234 - val_loss: 1.5452 - val_accuracy: 0.3571\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.0890 - accuracy: 0.3075 - val_loss: 1.4306 - val_accuracy: 0.3690\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.8176 - accuracy: 0.3155 - val_loss: 1.3985 - val_accuracy: 0.3810\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.6250 - accuracy: 0.3274 - val_loss: 1.6441 - val_accuracy: 0.3571\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.3818 - accuracy: 0.3234 - val_loss: 1.2053 - val_accuracy: 0.4464\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.0051 - accuracy: 0.3333 - val_loss: 1.2599 - val_accuracy: 0.3929\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.0992 - accuracy: 0.3135 - val_loss: 1.2581 - val_accuracy: 0.4464\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.8852 - accuracy: 0.3075 - val_loss: 1.1904 - val_accuracy: 0.4821\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.9492 - accuracy: 0.2857 - val_loss: 1.1970 - val_accuracy: 0.4643\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.6614 - accuracy: 0.3115 - val_loss: 1.2144 - val_accuracy: 0.4464\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4770 - accuracy: 0.3730 - val_loss: 1.2370 - val_accuracy: 0.4286\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2150 - accuracy: 0.3671 - val_loss: 1.2095 - val_accuracy: 0.4643\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2554 - accuracy: 0.3591 - val_loss: 1.2728 - val_accuracy: 0.4762\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2389 - accuracy: 0.3433 - val_loss: 1.2233 - val_accuracy: 0.5179\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2173 - accuracy: 0.3313 - val_loss: 1.2177 - val_accuracy: 0.5238\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.1303 - accuracy: 0.3571 - val_loss: 1.2100 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0291 - accuracy: 0.3512 - val_loss: 1.2041 - val_accuracy: 0.5060\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0644 - accuracy: 0.3333 - val_loss: 1.2171 - val_accuracy: 0.4940\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8478 - accuracy: 0.3611 - val_loss: 1.2258 - val_accuracy: 0.4821\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8952 - accuracy: 0.3353 - val_loss: 1.2251 - val_accuracy: 0.5119\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8421 - accuracy: 0.3393 - val_loss: 1.2512 - val_accuracy: 0.5179\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8324 - accuracy: 0.3512 - val_loss: 1.2476 - val_accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8203 - accuracy: 0.3472 - val_loss: 1.2685 - val_accuracy: 0.4821\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7684 - accuracy: 0.3512 - val_loss: 1.2514 - val_accuracy: 0.5238\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7388 - accuracy: 0.3671 - val_loss: 1.2713 - val_accuracy: 0.5119\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6347 - accuracy: 0.3591 - val_loss: 1.2854 - val_accuracy: 0.4524\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7172 - accuracy: 0.3730 - val_loss: 1.2962 - val_accuracy: 0.5298\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6654 - accuracy: 0.3353 - val_loss: 1.3240 - val_accuracy: 0.4881\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6422 - accuracy: 0.3532 - val_loss: 1.3150 - val_accuracy: 0.4405\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6175 - accuracy: 0.3651 - val_loss: 1.3178 - val_accuracy: 0.4464\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6381 - accuracy: 0.3651 - val_loss: 1.3016 - val_accuracy: 0.4464\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5487 - accuracy: 0.3750 - val_loss: 1.3224 - val_accuracy: 0.4286\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4637 - accuracy: 0.3651 - val_loss: 1.2906 - val_accuracy: 0.5417\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4693 - accuracy: 0.3968 - val_loss: 1.2766 - val_accuracy: 0.5357\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5118 - accuracy: 0.3690 - val_loss: 1.2664 - val_accuracy: 0.5060\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5688 - accuracy: 0.3591 - val_loss: 1.2721 - val_accuracy: 0.4940\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4112 - accuracy: 0.3948 - val_loss: 1.2593 - val_accuracy: 0.4881\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4436 - accuracy: 0.3968 - val_loss: 1.2759 - val_accuracy: 0.4702\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4984 - accuracy: 0.3571 - val_loss: 1.2796 - val_accuracy: 0.4643\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4901 - accuracy: 0.3452 - val_loss: 1.2781 - val_accuracy: 0.4583\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4942 - accuracy: 0.3690 - val_loss: 1.2568 - val_accuracy: 0.4881\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4150 - accuracy: 0.3690 - val_loss: 1.2538 - val_accuracy: 0.4643\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4364 - accuracy: 0.3730 - val_loss: 1.2184 - val_accuracy: 0.5595\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4169 - accuracy: 0.3829 - val_loss: 1.2339 - val_accuracy: 0.5417\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4655 - accuracy: 0.3790 - val_loss: 1.2219 - val_accuracy: 0.5060\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3764 - accuracy: 0.3988 - val_loss: 1.2419 - val_accuracy: 0.4940\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3973 - accuracy: 0.3790 - val_loss: 1.2419 - val_accuracy: 0.4702\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3604 - accuracy: 0.3988 - val_loss: 1.2273 - val_accuracy: 0.4702\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3925 - accuracy: 0.3988 - val_loss: 1.2283 - val_accuracy: 0.4821\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4076 - accuracy: 0.4147 - val_loss: 1.2391 - val_accuracy: 0.5119\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3567 - accuracy: 0.3770 - val_loss: 1.2519 - val_accuracy: 0.5417\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3561 - accuracy: 0.3810 - val_loss: 1.2337 - val_accuracy: 0.4643\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3546 - accuracy: 0.3810 - val_loss: 1.2426 - val_accuracy: 0.4643\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3545 - accuracy: 0.3988 - val_loss: 1.2635 - val_accuracy: 0.4702\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3650 - accuracy: 0.3849 - val_loss: 1.2697 - val_accuracy: 0.4702\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3191 - accuracy: 0.4107 - val_loss: 1.2804 - val_accuracy: 0.4881\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3020 - accuracy: 0.4127 - val_loss: 1.2782 - val_accuracy: 0.4940\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3487 - accuracy: 0.3790 - val_loss: 1.2681 - val_accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.3829 - val_loss: 1.2702 - val_accuracy: 0.4821\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3257 - accuracy: 0.3631 - val_loss: 1.2991 - val_accuracy: 0.5595\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3151 - accuracy: 0.4127 - val_loss: 1.2867 - val_accuracy: 0.5060\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3380 - accuracy: 0.3810 - val_loss: 1.2668 - val_accuracy: 0.5238\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3305 - accuracy: 0.3909 - val_loss: 1.2637 - val_accuracy: 0.5119\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3308 - accuracy: 0.3790 - val_loss: 1.2467 - val_accuracy: 0.5357\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2821 - accuracy: 0.3869 - val_loss: 1.2486 - val_accuracy: 0.5655\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3362 - accuracy: 0.3869 - val_loss: 1.2581 - val_accuracy: 0.5298\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3156 - accuracy: 0.3889 - val_loss: 1.2769 - val_accuracy: 0.5298\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2865 - accuracy: 0.4147 - val_loss: 1.2716 - val_accuracy: 0.5536\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3398 - accuracy: 0.3571 - val_loss: 1.2559 - val_accuracy: 0.5714\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3214 - accuracy: 0.4087 - val_loss: 1.2598 - val_accuracy: 0.5595\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2247 - accuracy: 0.4206 - val_loss: 1.2557 - val_accuracy: 0.4940\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2908 - accuracy: 0.3988 - val_loss: 1.2458 - val_accuracy: 0.5595\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2234 - accuracy: 0.4167 - val_loss: 1.2373 - val_accuracy: 0.5060\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2759 - accuracy: 0.4286 - val_loss: 1.2582 - val_accuracy: 0.5595\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2522 - accuracy: 0.4365 - val_loss: 1.2471 - val_accuracy: 0.5774\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2439 - accuracy: 0.3968 - val_loss: 1.2304 - val_accuracy: 0.5714\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2320 - accuracy: 0.4345 - val_loss: 1.2253 - val_accuracy: 0.5595\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2195 - accuracy: 0.4206 - val_loss: 1.2119 - val_accuracy: 0.5536\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2609 - accuracy: 0.4147 - val_loss: 1.2092 - val_accuracy: 0.5595\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2275 - accuracy: 0.4127 - val_loss: 1.2086 - val_accuracy: 0.5774\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2340 - accuracy: 0.4127 - val_loss: 1.2059 - val_accuracy: 0.5536\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2394 - accuracy: 0.4325 - val_loss: 1.2069 - val_accuracy: 0.5476\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2438 - accuracy: 0.4405 - val_loss: 1.2078 - val_accuracy: 0.5714\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2429 - accuracy: 0.3849 - val_loss: 1.2163 - val_accuracy: 0.5595\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1984 - accuracy: 0.4306 - val_loss: 1.2214 - val_accuracy: 0.5357\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2355 - accuracy: 0.4067 - val_loss: 1.2187 - val_accuracy: 0.5238\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2435 - accuracy: 0.4147 - val_loss: 1.2242 - val_accuracy: 0.4583\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2043 - accuracy: 0.4425 - val_loss: 1.2092 - val_accuracy: 0.4583\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2078 - accuracy: 0.4365 - val_loss: 1.1890 - val_accuracy: 0.5595\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1850 - accuracy: 0.4524 - val_loss: 1.1872 - val_accuracy: 0.5417\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1781 - accuracy: 0.4325 - val_loss: 1.1655 - val_accuracy: 0.5714\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1938 - accuracy: 0.4464 - val_loss: 1.1621 - val_accuracy: 0.5893\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1964 - accuracy: 0.4583 - val_loss: 1.1798 - val_accuracy: 0.6012\n"
          ]
        }
      ],
      "source": [
        "umhistory=um.fit(x_traincnn, y_train, batch_size=25, epochs=100, validation_data=(x_testcnn, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUtQ8Bwjhcmw",
        "outputId": "f6ba9567-9283-49b1-bd3a-235262048b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 1.1798 - accuracy: 0.6012\n",
            "Restored model, accuracy: 60.12%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = um.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqfstoLD8fPK",
        "outputId": "586582ba-ff0a-476b-8174-be856792dbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6011904761904762\n",
            "F1 score: 0.5683137292592346\n",
            "Recall: 0.6011904761904762\n",
            "Precision: 0.556192235910205\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.63      0.61        52\n",
            "         1.0       0.49      0.77      0.60        44\n",
            "         3.0       0.00      0.00      0.00        20\n",
            "         4.0       0.79      0.65      0.72        52\n",
            "\n",
            "    accuracy                           0.60       168\n",
            "   macro avg       0.47      0.52      0.48       168\n",
            "weighted avg       0.56      0.60      0.57       168\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[33 12  0  7]\n",
            " [ 8 34  0  2]\n",
            " [ 2 18  0  0]\n",
            " [13  5  0 34]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import confusion_matrix \n",
        "predict=um.predict(x_testcnn)\n",
        "classes=np.argmax(predict,axis=1)\n",
        "#print(classification_report(y_test,classes))\n",
        "#print(confusion_matrix(y_test,classes))\n",
        "print ('Accuracy:', accuracy_score(y_test, classes))\n",
        "print ('F1 score:', f1_score(y_test, classes,average='weighted'))\n",
        "print ('Recall:', recall_score(y_test, classes,average='weighted'))\n",
        "print ('Precision:', precision_score(y_test, classes,average='weighted'))\n",
        "print ('\\n clasification report:\\n', classification_report(y_test, classes))\n",
        "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFaGZGR16hDW",
        "outputId": "f6e01418-b33e-4b30-835f-c51b6a972678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP 34\n",
            "FP 35\n",
            "TN 33\n",
            "FP 23\n"
          ]
        }
      ],
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)\n",
        "res = perf_measure(y_test, classes)\n",
        "print(\"TP\",res[0])\n",
        "print(\"FP\",res[1])\n",
        "print(\"TN\",res[2])\n",
        "print(\"FP\",res[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "yWLQk_q7fyCM",
        "outputId": "bff64b11-6ae8-4c3c-f955-087c4c55e60f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "cm2 = pd.DataFrame(confusion_matrix(y_test, classes))\n",
        "plt.figure(figsize = (10, 8))\n",
        "sns.heatmap(cm2, annot = True, cbar = False, fmt = 'g')\n",
        "plt.ylabel('Actual values')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n78VEp7oh3BL",
        "outputId": "d2c6c2e4-bf72-4642-99d2-040d8db85693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result : sad\n"
          ]
        }
      ],
      "source": [
        "filename = \"/content/drive/My Drive/DataSets/audio_speech_actors_01-24/Actor_15/03-01-04-02-01-02-15.wav\"\n",
        "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
        "f=np.expand_dims(features,axis=2)\n",
        "predict=um.predict(f)\n",
        "classes=np.argmax(predict,axis=1)\n",
        "result=int(classes)\n",
        "print(\"result :\",em[result])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxQBQ5p-lRIx"
      },
      "source": [
        "# ***THIRD MODEL***\n",
        "\n",
        "Three Relu and one Softmax (Dropout=0.1)\n",
        "\n",
        "Sparse Categorial CrossEntropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgOckwmclKd5"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "tm = Sequential()\n",
        "\n",
        "tm.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
        "tm.add(Activation('relu'))\n",
        "tm.add(Dropout(0.1))\n",
        "tm.add(MaxPooling1D(pool_size=(8)))\n",
        "\n",
        "tm.add(Conv1D(128, 5,padding='same',))                  #2\n",
        "tm.add(Activation('relu'))\n",
        "tm.add(MaxPooling1D(pool_size=(8)))\n",
        "tm.add(Dropout(0.1))\n",
        "\n",
        "tm.add(Conv1D(128, 5,padding='same',))                  #3\n",
        "tm.add(Activation('relu'))\n",
        "tm.add(Dropout(0.1))\n",
        "\n",
        "tm.add(Flatten())\n",
        "tm.add(Dense(8))                                        #4                      \n",
        "tm.add(Activation('softmax'))\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.00005,epsilon=None,rho=0.9,decay=0.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL9SeCMYlPxJ",
        "outputId": "483548ad-9a47-400a-ef7b-704356bbf6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_25 (Conv1D)          (None, 180, 128)          768       \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 180, 128)          0         \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 180, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 22, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 22, 128)           82048     \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 22, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_16 (MaxPoolin  (None, 2, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 2056      \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 166,920\n",
            "Trainable params: 166,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB5d_vcQlatK"
      },
      "outputs": [],
      "source": [
        "tm.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYiVg5RPliiB",
        "outputId": "93dc2be3-139d-49fe-9db8-8eb90633126f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 1s 13ms/step - loss: 4.5623 - accuracy: 0.2560 - val_loss: 1.4256 - val_accuracy: 0.3214\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.2338 - accuracy: 0.3155 - val_loss: 1.4412 - val_accuracy: 0.3214\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.3634 - accuracy: 0.2956 - val_loss: 1.4846 - val_accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.1970 - accuracy: 0.3155 - val_loss: 1.4886 - val_accuracy: 0.4524\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.0426 - accuracy: 0.2599 - val_loss: 1.4263 - val_accuracy: 0.3571\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.6806 - accuracy: 0.3472 - val_loss: 1.3290 - val_accuracy: 0.3988\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4543 - accuracy: 0.3492 - val_loss: 1.3112 - val_accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.6680 - accuracy: 0.3155 - val_loss: 1.4996 - val_accuracy: 0.3452\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2969 - accuracy: 0.3413 - val_loss: 1.5002 - val_accuracy: 0.3929\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2699 - accuracy: 0.3274 - val_loss: 1.3290 - val_accuracy: 0.3512\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.1882 - accuracy: 0.3214 - val_loss: 1.3139 - val_accuracy: 0.3512\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0626 - accuracy: 0.3413 - val_loss: 1.4020 - val_accuracy: 0.3571\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8694 - accuracy: 0.3690 - val_loss: 1.4573 - val_accuracy: 0.3036\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.9420 - accuracy: 0.3274 - val_loss: 1.2258 - val_accuracy: 0.4464\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7782 - accuracy: 0.3532 - val_loss: 1.3071 - val_accuracy: 0.4048\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7399 - accuracy: 0.3472 - val_loss: 1.1973 - val_accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6013 - accuracy: 0.4048 - val_loss: 1.1592 - val_accuracy: 0.4107\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7035 - accuracy: 0.3552 - val_loss: 1.1983 - val_accuracy: 0.4464\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6358 - accuracy: 0.3651 - val_loss: 1.1414 - val_accuracy: 0.3988\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5131 - accuracy: 0.3810 - val_loss: 1.1048 - val_accuracy: 0.5119\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5200 - accuracy: 0.3591 - val_loss: 1.1938 - val_accuracy: 0.4226\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5232 - accuracy: 0.4107 - val_loss: 1.1807 - val_accuracy: 0.4643\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5228 - accuracy: 0.3492 - val_loss: 1.1568 - val_accuracy: 0.4226\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4422 - accuracy: 0.4127 - val_loss: 1.2016 - val_accuracy: 0.4226\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4337 - accuracy: 0.3690 - val_loss: 1.1862 - val_accuracy: 0.4940\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4261 - accuracy: 0.3929 - val_loss: 1.1868 - val_accuracy: 0.4226\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4714 - accuracy: 0.3790 - val_loss: 1.1822 - val_accuracy: 0.4702\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4224 - accuracy: 0.3750 - val_loss: 1.1525 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3927 - accuracy: 0.4147 - val_loss: 1.1076 - val_accuracy: 0.4405\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3875 - accuracy: 0.3710 - val_loss: 1.0997 - val_accuracy: 0.5060\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3543 - accuracy: 0.4167 - val_loss: 1.1633 - val_accuracy: 0.4643\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3716 - accuracy: 0.3889 - val_loss: 1.0927 - val_accuracy: 0.5357\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3544 - accuracy: 0.4147 - val_loss: 1.1484 - val_accuracy: 0.4464\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3214 - accuracy: 0.3948 - val_loss: 1.2397 - val_accuracy: 0.4048\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3375 - accuracy: 0.3889 - val_loss: 1.0869 - val_accuracy: 0.5536\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2630 - accuracy: 0.4286 - val_loss: 1.2025 - val_accuracy: 0.4286\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3590 - accuracy: 0.3829 - val_loss: 1.0846 - val_accuracy: 0.5357\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3017 - accuracy: 0.4147 - val_loss: 1.1703 - val_accuracy: 0.4464\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2444 - accuracy: 0.4107 - val_loss: 1.0564 - val_accuracy: 0.5298\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3096 - accuracy: 0.4385 - val_loss: 1.0891 - val_accuracy: 0.4821\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2568 - accuracy: 0.4325 - val_loss: 1.0878 - val_accuracy: 0.4881\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2578 - accuracy: 0.4405 - val_loss: 1.1070 - val_accuracy: 0.5238\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2329 - accuracy: 0.4405 - val_loss: 1.1075 - val_accuracy: 0.4702\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2712 - accuracy: 0.4028 - val_loss: 1.0696 - val_accuracy: 0.5476\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2491 - accuracy: 0.4187 - val_loss: 1.1078 - val_accuracy: 0.4286\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.4524 - val_loss: 1.0972 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2476 - accuracy: 0.4425 - val_loss: 1.1302 - val_accuracy: 0.4583\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2502 - accuracy: 0.4286 - val_loss: 1.1579 - val_accuracy: 0.4405\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2361 - accuracy: 0.4107 - val_loss: 1.0603 - val_accuracy: 0.5714\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2041 - accuracy: 0.4702 - val_loss: 1.0546 - val_accuracy: 0.5714\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1877 - accuracy: 0.4425 - val_loss: 1.0609 - val_accuracy: 0.5536\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1930 - accuracy: 0.4286 - val_loss: 1.0599 - val_accuracy: 0.5476\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2202 - accuracy: 0.4028 - val_loss: 1.0695 - val_accuracy: 0.5417\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.4603 - val_loss: 1.0476 - val_accuracy: 0.5655\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.4107 - val_loss: 1.0599 - val_accuracy: 0.5476\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1951 - accuracy: 0.4444 - val_loss: 1.0383 - val_accuracy: 0.5595\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1588 - accuracy: 0.4583 - val_loss: 1.0351 - val_accuracy: 0.5595\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2245 - accuracy: 0.4206 - val_loss: 1.0567 - val_accuracy: 0.5119\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1918 - accuracy: 0.4623 - val_loss: 1.0560 - val_accuracy: 0.5417\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1769 - accuracy: 0.4583 - val_loss: 1.0534 - val_accuracy: 0.5119\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1487 - accuracy: 0.4742 - val_loss: 1.0838 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1820 - accuracy: 0.4603 - val_loss: 1.0909 - val_accuracy: 0.5119\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1779 - accuracy: 0.4405 - val_loss: 1.0620 - val_accuracy: 0.5119\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1813 - accuracy: 0.4603 - val_loss: 1.0907 - val_accuracy: 0.5119\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2068 - accuracy: 0.4187 - val_loss: 1.0547 - val_accuracy: 0.5238\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1716 - accuracy: 0.4563 - val_loss: 1.0165 - val_accuracy: 0.6071\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1527 - accuracy: 0.4544 - val_loss: 1.0357 - val_accuracy: 0.5774\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1321 - accuracy: 0.4544 - val_loss: 1.0339 - val_accuracy: 0.5417\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1397 - accuracy: 0.4524 - val_loss: 1.0085 - val_accuracy: 0.6369\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1623 - accuracy: 0.4563 - val_loss: 1.0137 - val_accuracy: 0.5893\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1330 - accuracy: 0.4683 - val_loss: 1.0137 - val_accuracy: 0.6190\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1528 - accuracy: 0.4484 - val_loss: 1.0160 - val_accuracy: 0.5714\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1185 - accuracy: 0.4504 - val_loss: 1.0431 - val_accuracy: 0.5060\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1285 - accuracy: 0.4623 - val_loss: 1.0172 - val_accuracy: 0.5595\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1303 - accuracy: 0.4266 - val_loss: 1.0241 - val_accuracy: 0.5476\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1294 - accuracy: 0.4683 - val_loss: 1.0090 - val_accuracy: 0.5952\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1366 - accuracy: 0.4484 - val_loss: 1.0213 - val_accuracy: 0.5238\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1499 - accuracy: 0.4484 - val_loss: 1.0164 - val_accuracy: 0.5595\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1461 - accuracy: 0.4563 - val_loss: 0.9970 - val_accuracy: 0.5774\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1061 - accuracy: 0.4702 - val_loss: 1.0451 - val_accuracy: 0.5238\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1224 - accuracy: 0.4663 - val_loss: 1.0208 - val_accuracy: 0.5655\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1363 - accuracy: 0.4762 - val_loss: 1.0061 - val_accuracy: 0.5714\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1141 - accuracy: 0.4782 - val_loss: 0.9892 - val_accuracy: 0.6429\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1247 - accuracy: 0.4683 - val_loss: 1.0001 - val_accuracy: 0.5893\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0884 - accuracy: 0.4980 - val_loss: 1.0007 - val_accuracy: 0.5952\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0851 - accuracy: 0.5040 - val_loss: 1.0008 - val_accuracy: 0.5655\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1055 - accuracy: 0.4802 - val_loss: 1.0349 - val_accuracy: 0.5119\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0839 - accuracy: 0.4901 - val_loss: 1.0072 - val_accuracy: 0.5298\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0979 - accuracy: 0.4921 - val_loss: 1.0054 - val_accuracy: 0.5417\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1179 - accuracy: 0.5040 - val_loss: 0.9941 - val_accuracy: 0.5417\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0961 - accuracy: 0.4702 - val_loss: 0.9998 - val_accuracy: 0.5417\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0910 - accuracy: 0.4821 - val_loss: 0.9881 - val_accuracy: 0.6131\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1012 - accuracy: 0.4901 - val_loss: 1.0125 - val_accuracy: 0.5357\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.4960 - val_loss: 1.0174 - val_accuracy: 0.5655\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0907 - accuracy: 0.4742 - val_loss: 0.9820 - val_accuracy: 0.6012\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1063 - accuracy: 0.4583 - val_loss: 1.0075 - val_accuracy: 0.5536\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0644 - accuracy: 0.5139 - val_loss: 0.9969 - val_accuracy: 0.5595\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0846 - accuracy: 0.4544 - val_loss: 1.0010 - val_accuracy: 0.5060\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0532 - accuracy: 0.5000 - val_loss: 0.9974 - val_accuracy: 0.5655\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0598 - accuracy: 0.4821 - val_loss: 0.9788 - val_accuracy: 0.5536\n"
          ]
        }
      ],
      "source": [
        "tmhistory=tm.fit(x_traincnn, y_train, batch_size=25, epochs=100, validation_data=(x_testcnn, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbbY3j68lmVR",
        "outputId": "83805dbe-ba0e-4f83-c8d4-d5624228d0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9788 - accuracy: 0.5536\n",
            "Restored model, accuracy: 55.36%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = tm.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mL8z3EQ9jZT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import confusion_matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3GIvS2nWRFz",
        "outputId": "e0e9bf0f-d6aa-4827-d892-aba72180d151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5535714285714286\n",
            "F1 score: 0.5531394166862147\n",
            "Recall: 0.5535714285714286\n",
            "Precision: 0.572387643582023\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.42      0.51        52\n",
            "         1.0       0.44      0.61      0.51        44\n",
            "         3.0       0.40      0.40      0.40        20\n",
            "         4.0       0.69      0.69      0.69        52\n",
            "\n",
            "    accuracy                           0.55       168\n",
            "   macro avg       0.54      0.53      0.53       168\n",
            "weighted avg       0.57      0.55      0.55       168\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[22 15  1 14]\n",
            " [ 5 27 11  1]\n",
            " [ 0 11  8  1]\n",
            " [ 8  8  0 36]]\n"
          ]
        }
      ],
      "source": [
        "pred=tm.predict(x_testcnn)\n",
        "clas=np.argmax(pred,axis=1)\n",
        "#print(classification_report(y_test,clas))\n",
        "#print(confusion_matrix(y_test,clas))\n",
        "print ('Accuracy:', accuracy_score(y_test, clas))\n",
        "print ('F1 score:', f1_score(y_test, clas,average='weighted'))\n",
        "print ('Recall:', recall_score(y_test, clas,average='weighted'))\n",
        "print ('Precision:', precision_score(y_test, clas,average='weighted'))\n",
        "print ('\\n clasification report:\\n', classification_report(y_test, clas))\n",
        "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, clas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpeuPFZg6nGu",
        "outputId": "421a5ce0-0dfd-4bd9-e9d9-e732df5d4b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP 27\n",
            "FP 34\n",
            "TN 22\n",
            "FP 13\n"
          ]
        }
      ],
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)\n",
        "res = perf_measure(y_test, clas)\n",
        "print(\"TP\",res[0])\n",
        "print(\"FP\",res[1])\n",
        "print(\"TN\",res[2])\n",
        "print(\"FP\",res[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "CPSnXPwVgHfe",
        "outputId": "8a3215ab-ee01-482a-b2ae-83e99f642f30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "cm3 = pd.DataFrame(confusion_matrix(y_test, clas))\n",
        "plt.figure(figsize = (10, 8))\n",
        "sns.heatmap(cm3, annot = True, cbar = False, fmt = 'g')\n",
        "plt.ylabel('Actual values')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDjPv_kqi3TA",
        "outputId": "9aee65da-e26f-425a-f138-9c7818b9e7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result : angry\n"
          ]
        }
      ],
      "source": [
        "filename = \"/content/drive/My Drive/DataSets/audio_speech_actors_01-24/Actor_04/03-01-03-01-02-02-04.wav\"\n",
        "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
        "f=np.expand_dims(features,axis=2)\n",
        "pred=tm.predict(f)\n",
        "clas=np.argmax(pred,axis=1)\n",
        "result=int(clas-1)\n",
        "print(\"result :\",em[result])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abdy_mt4nABa"
      },
      "source": [
        "# ***FORTH MODEL***\n",
        "\n",
        "Four Relu and one Softmax\n",
        "\n",
        "Sparse Categorial CrossEntropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V43ptFvXm-bj",
        "outputId": "a25cc695-fbcd-48d6-f264-f5e613e39f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "sm = Sequential()\n",
        "\n",
        "sm.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
        "sm.add(Activation('relu'))\n",
        "sm.add(Dropout(0.1))\n",
        "sm.add(MaxPooling1D(pool_size=(8)))\n",
        "\n",
        "sm.add(Conv1D(128, 5,padding='same',))                  #2\n",
        "sm.add(Activation('relu'))\n",
        "sm.add(MaxPooling1D(pool_size=(8)))\n",
        "sm.add(Dropout(0.1))\n",
        "\n",
        "sm.add(Conv1D(128, 5,padding='same',))                  #3\n",
        "sm.add(Activation('relu'))\n",
        "sm.add(Dropout(0.1))\n",
        "\n",
        "sm.add(Conv1D(128, 5,padding='same',))                  #4\n",
        "sm.add(Activation('relu'))\n",
        "sm.add(Dropout(0.1))\n",
        "\n",
        "sm.add(Flatten())\n",
        "sm.add(Dense(8))                                        #5                     \n",
        "sm.add(Activation('softmax'))\n",
        "opt = keras.optimizers.RMSprop(lr=0.00005,epsilon=None,rho=0.9,decay=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKvLhSPPnG6C",
        "outputId": "ffdde8e0-858b-4327-aae3-47dc742e833a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_28 (Conv1D)          (None, 180, 128)          768       \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 180, 128)          0         \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 180, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 22, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 22, 128)           82048     \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 22, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 2, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " conv1d_30 (Conv1D)          (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 2, 128)            0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 2056      \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 248,968\n",
            "Trainable params: 248,968\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPJIfLcGnH0x"
      },
      "outputs": [],
      "source": [
        "sm.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K51eTwPjnIGJ",
        "outputId": "df02ef26-6e1c-4d86-f855-cccf61889c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 1s 15ms/step - loss: 3.5676 - accuracy: 0.1905 - val_loss: 1.4606 - val_accuracy: 0.2619\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.1204 - accuracy: 0.2996 - val_loss: 1.8785 - val_accuracy: 0.3095\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1.9535 - accuracy: 0.3056 - val_loss: 1.4932 - val_accuracy: 0.3095\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.9393 - accuracy: 0.2917 - val_loss: 1.4484 - val_accuracy: 0.3095\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.7532 - accuracy: 0.3274 - val_loss: 1.3519 - val_accuracy: 0.4345\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6940 - accuracy: 0.3373 - val_loss: 1.4347 - val_accuracy: 0.3095\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6195 - accuracy: 0.3433 - val_loss: 1.2813 - val_accuracy: 0.3690\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5843 - accuracy: 0.3611 - val_loss: 1.2721 - val_accuracy: 0.3810\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.5028 - accuracy: 0.3651 - val_loss: 1.2662 - val_accuracy: 0.4286\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.5118 - accuracy: 0.3234 - val_loss: 1.2459 - val_accuracy: 0.4881\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4673 - accuracy: 0.3155 - val_loss: 1.3172 - val_accuracy: 0.3095\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.4663 - accuracy: 0.3353 - val_loss: 1.2622 - val_accuracy: 0.3274\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4331 - accuracy: 0.3611 - val_loss: 1.2762 - val_accuracy: 0.4048\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4200 - accuracy: 0.3552 - val_loss: 1.2180 - val_accuracy: 0.4464\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3870 - accuracy: 0.3710 - val_loss: 1.2484 - val_accuracy: 0.4167\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3549 - accuracy: 0.3750 - val_loss: 1.2003 - val_accuracy: 0.4881\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.4094 - accuracy: 0.3254 - val_loss: 1.2325 - val_accuracy: 0.3452\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3210 - accuracy: 0.4008 - val_loss: 1.2513 - val_accuracy: 0.4226\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3341 - accuracy: 0.3651 - val_loss: 1.1961 - val_accuracy: 0.5238\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3622 - accuracy: 0.3790 - val_loss: 1.2420 - val_accuracy: 0.3095\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3564 - accuracy: 0.3988 - val_loss: 1.2048 - val_accuracy: 0.4464\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3402 - accuracy: 0.3810 - val_loss: 1.1729 - val_accuracy: 0.5060\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3101 - accuracy: 0.3671 - val_loss: 1.1866 - val_accuracy: 0.4524\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2916 - accuracy: 0.3988 - val_loss: 1.2146 - val_accuracy: 0.3452\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3026 - accuracy: 0.3810 - val_loss: 1.1585 - val_accuracy: 0.5238\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2652 - accuracy: 0.4008 - val_loss: 1.2066 - val_accuracy: 0.3274\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3080 - accuracy: 0.3968 - val_loss: 1.1803 - val_accuracy: 0.4821\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3010 - accuracy: 0.3770 - val_loss: 1.1591 - val_accuracy: 0.5238\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3178 - accuracy: 0.3651 - val_loss: 1.1748 - val_accuracy: 0.4226\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2783 - accuracy: 0.3968 - val_loss: 1.1523 - val_accuracy: 0.4464\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2293 - accuracy: 0.4286 - val_loss: 1.1522 - val_accuracy: 0.5655\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2971 - accuracy: 0.3889 - val_loss: 1.1327 - val_accuracy: 0.5417\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2779 - accuracy: 0.3889 - val_loss: 1.1521 - val_accuracy: 0.4821\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2378 - accuracy: 0.3988 - val_loss: 1.1359 - val_accuracy: 0.4940\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2562 - accuracy: 0.4167 - val_loss: 1.1526 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2388 - accuracy: 0.4365 - val_loss: 1.1218 - val_accuracy: 0.5417\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2302 - accuracy: 0.4306 - val_loss: 1.1457 - val_accuracy: 0.5060\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.4345 - val_loss: 1.1104 - val_accuracy: 0.5298\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2365 - accuracy: 0.4226 - val_loss: 1.1340 - val_accuracy: 0.5298\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2336 - accuracy: 0.4167 - val_loss: 1.1266 - val_accuracy: 0.4940\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2559 - accuracy: 0.4028 - val_loss: 1.1407 - val_accuracy: 0.5060\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2644 - accuracy: 0.4127 - val_loss: 1.1294 - val_accuracy: 0.4643\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2100 - accuracy: 0.4286 - val_loss: 1.1253 - val_accuracy: 0.4702\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1834 - accuracy: 0.4524 - val_loss: 1.1269 - val_accuracy: 0.5238\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2285 - accuracy: 0.3948 - val_loss: 1.1104 - val_accuracy: 0.5060\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1960 - accuracy: 0.4365 - val_loss: 1.0907 - val_accuracy: 0.5893\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.4206 - val_loss: 1.0853 - val_accuracy: 0.5298\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2103 - accuracy: 0.4405 - val_loss: 1.0917 - val_accuracy: 0.5536\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2104 - accuracy: 0.4167 - val_loss: 1.1178 - val_accuracy: 0.5179\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1905 - accuracy: 0.4444 - val_loss: 1.1182 - val_accuracy: 0.5298\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1942 - accuracy: 0.4266 - val_loss: 1.0980 - val_accuracy: 0.5417\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2014 - accuracy: 0.4067 - val_loss: 1.0879 - val_accuracy: 0.5714\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2034 - accuracy: 0.4107 - val_loss: 1.0921 - val_accuracy: 0.5536\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1681 - accuracy: 0.4405 - val_loss: 1.1177 - val_accuracy: 0.5298\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1901 - accuracy: 0.4286 - val_loss: 1.0952 - val_accuracy: 0.5655\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1906 - accuracy: 0.4425 - val_loss: 1.0699 - val_accuracy: 0.5595\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1721 - accuracy: 0.4663 - val_loss: 1.0818 - val_accuracy: 0.5476\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1826 - accuracy: 0.4425 - val_loss: 1.1025 - val_accuracy: 0.4762\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1517 - accuracy: 0.4683 - val_loss: 1.1246 - val_accuracy: 0.4345\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1916 - accuracy: 0.4345 - val_loss: 1.0637 - val_accuracy: 0.5655\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1938 - accuracy: 0.4563 - val_loss: 1.0756 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1824 - accuracy: 0.4286 - val_loss: 1.0783 - val_accuracy: 0.5179\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1579 - accuracy: 0.4563 - val_loss: 1.0633 - val_accuracy: 0.5179\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1663 - accuracy: 0.4563 - val_loss: 1.0525 - val_accuracy: 0.5714\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1546 - accuracy: 0.4722 - val_loss: 1.0773 - val_accuracy: 0.4940\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1582 - accuracy: 0.4484 - val_loss: 1.0641 - val_accuracy: 0.5417\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1284 - accuracy: 0.4563 - val_loss: 1.0608 - val_accuracy: 0.5238\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1525 - accuracy: 0.4683 - val_loss: 1.0796 - val_accuracy: 0.5357\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1428 - accuracy: 0.4683 - val_loss: 1.0489 - val_accuracy: 0.5714\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1597 - accuracy: 0.4504 - val_loss: 1.0930 - val_accuracy: 0.4762\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1361 - accuracy: 0.4643 - val_loss: 1.0819 - val_accuracy: 0.4940\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1777 - accuracy: 0.4484 - val_loss: 1.0832 - val_accuracy: 0.5476\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1189 - accuracy: 0.4623 - val_loss: 1.0691 - val_accuracy: 0.5060\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1297 - accuracy: 0.4524 - val_loss: 1.0440 - val_accuracy: 0.5655\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1468 - accuracy: 0.4325 - val_loss: 1.0407 - val_accuracy: 0.5119\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1128 - accuracy: 0.4623 - val_loss: 1.1269 - val_accuracy: 0.4405\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1244 - accuracy: 0.4603 - val_loss: 1.0248 - val_accuracy: 0.5655\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0996 - accuracy: 0.4702 - val_loss: 1.0614 - val_accuracy: 0.5238\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1155 - accuracy: 0.4484 - val_loss: 1.0116 - val_accuracy: 0.5893\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1474 - accuracy: 0.4563 - val_loss: 1.0166 - val_accuracy: 0.5833\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1247 - accuracy: 0.4940 - val_loss: 1.0154 - val_accuracy: 0.5536\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1048 - accuracy: 0.4980 - val_loss: 1.0415 - val_accuracy: 0.5357\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1404 - accuracy: 0.4544 - val_loss: 1.0397 - val_accuracy: 0.4762\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1049 - accuracy: 0.4563 - val_loss: 1.0056 - val_accuracy: 0.5417\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1133 - accuracy: 0.4425 - val_loss: 1.0170 - val_accuracy: 0.5595\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1043 - accuracy: 0.4464 - val_loss: 1.0097 - val_accuracy: 0.5655\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1311 - accuracy: 0.4623 - val_loss: 1.0565 - val_accuracy: 0.4524\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.0818 - accuracy: 0.4980 - val_loss: 1.0312 - val_accuracy: 0.4881\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.0838 - accuracy: 0.4702 - val_loss: 0.9939 - val_accuracy: 0.6012\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1139 - accuracy: 0.4544 - val_loss: 0.9787 - val_accuracy: 0.5774\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1108 - accuracy: 0.4702 - val_loss: 0.9822 - val_accuracy: 0.6012\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0778 - accuracy: 0.4583 - val_loss: 1.0163 - val_accuracy: 0.5476\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.0775 - accuracy: 0.4901 - val_loss: 1.0137 - val_accuracy: 0.5179\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1095 - accuracy: 0.4484 - val_loss: 1.0006 - val_accuracy: 0.5476\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1156 - accuracy: 0.4683 - val_loss: 1.0178 - val_accuracy: 0.5179\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.1062 - accuracy: 0.4861 - val_loss: 1.0307 - val_accuracy: 0.5060\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1.0759 - accuracy: 0.4762 - val_loss: 1.0055 - val_accuracy: 0.5417\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0847 - accuracy: 0.4821 - val_loss: 0.9890 - val_accuracy: 0.5655\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.0774 - accuracy: 0.4841 - val_loss: 1.0071 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1037 - accuracy: 0.4563 - val_loss: 0.9856 - val_accuracy: 0.5655\n"
          ]
        }
      ],
      "source": [
        "smhistory=sm.fit(x_traincnn, y_train, batch_size=25, epochs=100, validation_data=(x_testcnn, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBS8v4sWnIjJ",
        "outputId": "72e76def-241a-42c4-bece-672e686f8bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9856 - accuracy: 0.5655\n",
            "Restored model, accuracy: 56.55%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = sm.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKQ7YEL693jZ",
        "outputId": "f8aca9e9-a619-47f0-9418-cf1d73cbacc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5654761904761905\n",
            "F1 score: 0.5387239033544453\n",
            "Recall: 0.5654761904761905\n",
            "Precision: 0.5215404096421178\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.65      0.59        52\n",
            "         1.0       0.46      0.59      0.52        44\n",
            "         3.0       0.00      0.00      0.00        20\n",
            "         4.0       0.76      0.67      0.71        52\n",
            "\n",
            "    accuracy                           0.57       168\n",
            "   macro avg       0.44      0.48      0.46       168\n",
            "weighted avg       0.52      0.57      0.54       168\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[34  7  0 11]\n",
            " [16 26  2  0]\n",
            " [ 1 19  0  0]\n",
            " [13  4  0 35]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import confusion_matrix \n",
        "des=sm.predict(x_testcnn)\n",
        "obj=np.argmax(des,axis=1)\n",
        "#print(classification_report(y_test,obj))\n",
        "#print(confusion_matrix(y_test,obj))\n",
        "print ('Accuracy:', accuracy_score(y_test, obj))\n",
        "print ('F1 score:', f1_score(y_test, obj,average='weighted'))\n",
        "print ('Recall:', recall_score(y_test, obj,average='weighted'))\n",
        "print ('Precision:', precision_score(y_test, obj,average='weighted'))\n",
        "print ('\\n clasification report:\\n', classification_report(y_test, obj))\n",
        "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, obj))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAIliX-e6t_W",
        "outputId": "50df678e-e176-474d-a409-96fa93751f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP 26\n",
            "FP 30\n",
            "TN 34\n",
            "FP 30\n"
          ]
        }
      ],
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)\n",
        "res = perf_measure(y_test, obj)\n",
        "print(\"TP\",res[0])\n",
        "print(\"FP\",res[1])\n",
        "print(\"TN\",res[2])\n",
        "print(\"FP\",res[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "vj7lLJXDgRwj",
        "outputId": "1bc33bc4-45df-4a99-e592-f9a71bc2dbfc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "cm4 = pd.DataFrame(confusion_matrix(y_test, obj))\n",
        "plt.figure(figsize = (10, 8))\n",
        "sns.heatmap(cm4, annot = True, cbar = False, fmt = 'g')\n",
        "plt.ylabel('Actual values')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G6hnPFmi-hL",
        "outputId": "b9556fe0-b18a-4d09-9062-ed6df759802a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result : angry\n"
          ]
        }
      ],
      "source": [
        "filename = \"/content/drive/My Drive/DataSets/audio_speech_actors_01-24/Actor_23/03-01-01-01-02-02-23.wav\"\n",
        "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
        "f=np.expand_dims(features,axis=2)\n",
        "des=sm.predict(f)\n",
        "obj=np.argmax(des,axis=1)\n",
        "result=int(obj)-1\n",
        "print(\"result :\",em[result])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W3q2VX0H99hD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Speech Emotion Recongnization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}